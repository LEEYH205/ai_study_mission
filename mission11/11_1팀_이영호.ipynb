{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d417a53",
   "metadata": {},
   "source": [
    "# 미션 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f51d5f",
   "metadata": {},
   "source": [
    "기계 번역 실습으로, 한국어 문장을 영어로 번역하는 모델을 구축\n",
    "\n",
    "총 3가지 모델(Seq2Seq 기본 모델, Attention 적용 모델)을 구현하고 학습시키며, 각 모델의 성능을 비교 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a95193",
   "metadata": {},
   "source": [
    "JSON 파일 형식으로 제공되며, 각 항목은 한국어 문장(\"ko\")과 영어 번역문(\"mt\")으로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d20eb",
   "metadata": {},
   "source": [
    "## 가이드라인\n",
    "- 데이터 전처리\n",
    "    - 적절한 토크나이저를 선택하여 한국어, 영어 문장을 토큰화하세요.\n",
    "    - 문장 길이를 분석하여, 전체 문장의 길이에 맞게 최대 길이(MAX_LENGTH)를 설정하고, 필요한 경우 SOS, EOS, PAD, UNK 등의 특수 토큰을 정의한다.\n",
    "- 어휘 사전 구축\n",
    "    - 한국어와 영어 각각의 어후 사전을 구성\n",
    "    - 단어의 등장 빈도를 고려하여, 추후 임베딩이나 기타 모델 구성에 활용할 수 있다.\n",
    "- 텐서 변환 및 데이터 로더 구현\n",
    "    - 각 문장을 토큰의 인덱스 시퀀스로 변환한 후, 고정 길이에 맞게 PAD 토큰으로 패딩한다.\n",
    "    - `TensorDataset`과 `DataLoader`를 활용하여 학습 데이터를 배치 단위로 효율적으로 처리할 수 있도록 구현\n",
    "- 모델 구현 및 실습\n",
    "    - Seq2Seq 모델\n",
    "        - 기본 GRU 기반의 Encoder-Decoder 모델을 구현하고, Teacher Forcing 기법을 적용해 학습한다.\n",
    "    - Attention 모델\n",
    "        - Bahdanau Attention(Bahdanau 혹은 Luong)을 적용한 디코더를 구현하여, 번역 성능을 높이기\n",
    "- 모델 학습 및 평가\n",
    "    - 각 모델별로 학습을 진행한 후, 평가 함수를 활용하여 번역 결과를 확인한다.\n",
    "    - 무작위 문장 쌍에 대해 모델의 변역 결과를 출력하고, 출력 문장을 정제(특수 토큰 제거 등)하여 성능을 분석\n",
    "- 모델 성능 개선 (심화)\n",
    "    - 데이터 전처리 방법 개선(예:불용어 제거, 정규화 등)\n",
    "    - 모델 구조 변경(레이어 수, 은닉 상태 크기, Attention 기법 수정 등)\n",
    "    - 하이퍼파라미터 튜닝(학습률, 배치 크기 등)\n",
    "    - 다양한 평가 지표(예: BLEU 점수) 도입"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1364a",
   "metadata": {},
   "source": [
    "# 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333d03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n",
      "Requirement already satisfied: konlpy in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from konlpy) (1.5.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from konlpy) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y mecab mecab-ipadic-utf8 libmecab-dev\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335b54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47439e",
   "metadata": {},
   "source": [
    "## GPU 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379ab93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0\n",
      "MPS available: True\n",
      "CUDA available: False\n",
      "Using MPS (Apple Silicon GPU)\n",
      "Selected device: mps\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # 맥북 M1/M2 GPU\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU (Colab, Windows 등)\n",
    "    print(\"Using CUDA (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # CPU fallback\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"Selected device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75919429",
   "metadata": {},
   "source": [
    "## 한국어 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebde9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나눔 폰트를 성공적으로 설정했습니다.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 나눔 폰트가 없는 경우를 대비한 대체 폰트 설정\n",
    "try:\n",
    "    # 나눔 폰트가 설치되어 있는지 확인\n",
    "    path = '../NanumGothic.ttf'\n",
    "    font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
    "    plt.rc('font', family=font_name)\n",
    "    fm.fontManager.addfont(path)\n",
    "    print(\"나눔 폰트를 성공적으로 설정했습니다.\")\n",
    "except:\n",
    "    # 나눔 폰트가 없는 경우 기본 폰트 사용\n",
    "    print(\"나눔 폰트를 찾을 수 없습니다. 기본 폰트를 사용합니다.\")\n",
    "    plt.rc('font', family='DejaVu Sans')  # 기본 폰트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fe40f",
   "metadata": {},
   "source": [
    "# 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdfbc89",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d326a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK 데이터 경로: /Users/leeyoungho/develop/ai_study/mission/mission11/nltk_data\n",
      "경로 존재 여부: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/leeyoungho/develop/ai_\n",
      "[nltk_data]     study/mission/mission11/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/leeyoungho/develop\n",
      "[nltk_data]     /ai_study/mission/mission11/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK 데이터를 현재 폴더의 nltk_data 디렉토리에 다운로드\n",
    "current_dir = os.getcwd()\n",
    "nltk_data_dir = os.path.join(current_dir, 'nltk_data')\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "print(f\"NLTK 데이터 경로: {nltk_data_dir}\")\n",
    "print(f\"경로 존재 여부: {os.path.exists(nltk_data_dir)}\")\n",
    "\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522b868",
   "metadata": {},
   "source": [
    "## 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556c0aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117b50290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995378d",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad050b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 경로:\n",
      "훈련 데이터: ./일상생활및구어체_한영/일상생활및구어체_한영_train_set.json\n",
      "검증 데이터: ./일상생활및구어체_한영/일상생활및구어체_한영_valid_set.json\n"
     ]
    }
   ],
   "source": [
    "train_json_file_path = \"./일상생활및구어체_한영/일상생활및구어체_한영_train_set.json\"\n",
    "valid_json_file_path = \"./일상생활및구어체_한영/일상생활및구어체_한영_valid_set.json\"\n",
    "\n",
    "# 결과 저장 폴더 생성\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "print(\"데이터 경로:\")\n",
    "print(f\"훈련 데이터: {train_json_file_path}\")\n",
    "print(f\"검증 데이터: {valid_json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f9926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터 로딩 중 ===\n",
      "로드된 데이터 개수: 10000\n",
      "로드된 데이터 개수: 1000\n",
      "훈련 데이터: 한국어 10000개, 영어 10000개\n",
      "검증 데이터: 한국어 1000개, 영어 1000개\n"
     ]
    }
   ],
   "source": [
    "def load_json(file_path, max_samples=None):\n",
    "    \"\"\"JSON 파일을 로드하고 데이터 추출\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if max_samples:\n",
    "            data = data[\"data\"][:max_samples]\n",
    "        else:\n",
    "            data = data[\"data\"]\n",
    "            \n",
    "        print(f\"로드된 데이터 개수: {len(data)}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 로딩 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "# 데이터 로드\n",
    "print(\"=== 데이터 로딩 중 ===\")\n",
    "data_train = load_json(train_json_file_path, max_samples=10000)\n",
    "data_valid = load_json(valid_json_file_path, max_samples=1000)\n",
    "\n",
    "# ko와 mt 데이터 추출\n",
    "ko_sentences_train = [item[\"ko\"] for item in data_train]\n",
    "mt_sentences_train = [item[\"mt\"] for item in data_train]\n",
    "ko_sentences_valid = [item[\"ko\"] for item in data_valid]\n",
    "mt_sentences_valid = [item[\"mt\"] for item in data_valid]\n",
    "\n",
    "print(f\"훈련 데이터: 한국어 {len(ko_sentences_train)}개, 영어 {len(mt_sentences_train)}개\")\n",
    "print(f\"검증 데이터: 한국어 {len(ko_sentences_valid)}개, 영어 {len(mt_sentences_valid)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715459f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: ['sn', 'data_set', 'domain', 'subdomain', 'ko_original', 'ko', 'mt', 'en', 'source_language', 'target_language', 'word_count_ko', 'word_count_en', 'word_ratio', 'file_name', 'source', 'license', 'style', 'included_unknown_words', 'ner']\n",
      "Value: {'sn': 'INTSALDSUT062119042703238', 'data_set': '일상생활및구어체', 'domain': '해외영업', 'subdomain': '도소매유통', 'ko_original': '원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.', 'ko': '원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.', 'mt': 'If you reply to the color you want, we will start making it right away.', 'en': 'If you reply to the color you want, we will start making it right away.', 'source_language': 'ko', 'target_language': 'en', 'word_count_ko': 7, 'word_count_en': 15, 'word_ratio': 2.143, 'file_name': 'INTSAL_DSUT.xlsx', 'source': '크라우드소싱', 'license': 'open', 'style': '구어체', 'included_unknown_words': False, 'ner': None}\n",
      "\n",
      "Key: ['sn', 'data_set', 'domain', 'subdomain', 'ko_original', 'ko', 'mt', 'en', 'source_language', 'target_language', 'word_count_ko', 'word_count_en', 'word_ratio', 'file_name', 'source', 'license', 'style', 'included_unknown_words', 'ner']\n",
      "Value: {'sn': 'KTOS062012215138740', 'data_set': '일상생활및구어체', 'domain': '일상생활', 'subdomain': '여행', 'ko_original': '>아, 진짜요?', 'ko': '>아, 진짜요?', 'mt': 'Oh, really?', 'en': '>Oh, really?', 'source_language': 'ko', 'target_language': 'en', 'word_count_ko': 2, 'word_count_en': 2, 'word_ratio': 1.0, 'file_name': '여행_KTOS.xlsx', 'source': 'SBS', 'license': 'open', 'style': '구어체', 'included_unknown_words': False, 'ner': None}\n"
     ]
    }
   ],
   "source": [
    "if len(data_train) > 0:\n",
    "    print(f\"Key: {list(data_train[0].keys())}\")\n",
    "    print(f\"Value: {data_train[0]}\")\n",
    "    print()\n",
    "\n",
    "if len(data_valid) > 0:\n",
    "    print(f\"Key: {list(data_valid[0].keys())}\")\n",
    "    print(f\"Value: {data_valid[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e284dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터 샘플 ===\n",
      "샘플 1:\n",
      "  한국어: 원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.\n",
      "  영어: If you reply to the color you want, we will start making it right away.\n",
      "\n",
      "샘플 2:\n",
      "  한국어: 형님 제일 웃긴 그림이 뭔지 알아요.\n",
      "  영어: I know what the funniest picture is.\n",
      "\n",
      "샘플 3:\n",
      "  한국어: >속옷을?\n",
      "  영어: Underwear?\n",
      "\n",
      "샘플 4:\n",
      "  한국어: 그래도 가격이 꽤 비싸니까 많이 살게요.\n",
      "  영어: However, the price is quite high, so I will buy a lot.\n",
      "\n",
      "샘플 5:\n",
      "  한국어: AAA님, 제가 회의에서 화를 냈던 점 정말 사과드리고 싶습니다.\n",
      "  영어: AAA, I really want to apologize for being upset at the meeting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 샘플 확인\n",
    "print(\"=== 데이터 샘플 ===\")\n",
    "for i in range(min(5, len(data_train))):\n",
    "    print(f\"샘플 {i+1}:\")\n",
    "    print(f\"  한국어: {ko_sentences_train[i]}\")\n",
    "    print(f\"  영어: {mt_sentences_train[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b33a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 토크나이저 테스트 ===\n",
      "한국어 토큰화: 안녕하세요 오늘 날씨가 좋네요 -> ['안녕하세요', '오늘', '날씨', '가', '좋네요']\n",
      "영어 토큰화: Hello, how are you today? -> ['Hello', ',', 'how', 'are', 'you', 'today', '?']\n"
     ]
    }
   ],
   "source": [
    "# 한국어 및 영어 토크나이저 설정\n",
    "tokenizer_ko = Okt().morphs\n",
    "tokenizer_en = word_tokenize\n",
    "\n",
    "# 토크나이저 테스트\n",
    "print(\"=== 토크나이저 테스트 ===\")\n",
    "test_ko = \"안녕하세요 오늘 날씨가 좋네요\"\n",
    "test_en = \"Hello, how are you today?\"\n",
    "\n",
    "print(f\"한국어 토큰화: {test_ko} -> {tokenizer_ko(test_ko)}\")\n",
    "print(f\"영어 토큰화: {test_en} -> {tokenizer_en(test_en)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07636184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 문장 길이 분석 ===\n",
      "한국어 문장 길이 통계:\n",
      "  최소: 1\n",
      "  최대: 51\n",
      "  평균: 11.27\n",
      "  중간값: 10.00\n",
      "\n",
      "영어 문장 길이 통계:\n",
      "  최소: 1\n",
      "  최대: 51\n",
      "  평균: 11.64\n",
      "  중간값: 11.00\n",
      "\n",
      "설정된 MAX_LENGTH: 25\n"
     ]
    }
   ],
   "source": [
    "# 문장 길이 분석\n",
    "print(\"=== 문장 길이 분석 ===\")\n",
    "ko_lengths = [len(tokenizer_ko(sent)) for sent in ko_sentences_train]\n",
    "en_lengths = [len(tokenizer_en(sent)) for sent in mt_sentences_train]\n",
    "\n",
    "print(f\"한국어 문장 길이 통계:\")\n",
    "print(f\"  최소: {min(ko_lengths)}\")\n",
    "print(f\"  최대: {max(ko_lengths)}\")\n",
    "print(f\"  평균: {np.mean(ko_lengths):.2f}\")\n",
    "print(f\"  중간값: {np.median(ko_lengths):.2f}\")\n",
    "\n",
    "print(f\"\\n영어 문장 길이 통계:\")\n",
    "print(f\"  최소: {min(en_lengths)}\")\n",
    "print(f\"  최대: {max(en_lengths)}\")\n",
    "print(f\"  평균: {np.mean(en_lengths):.2f}\")\n",
    "print(f\"  중간값: {np.median(en_lengths):.2f}\")\n",
    "\n",
    "# MAX_LENGTH 설정 (95% 백분위수 기준)\n",
    "ko_95th = np.percentile(ko_lengths, 95)\n",
    "en_95th = np.percentile(en_lengths, 95)\n",
    "MAX_LENGTH = int(max(ko_95th, en_95th)) + 2  # SOS, EOS 토큰 포함\n",
    "\n",
    "print(f\"\\n설정된 MAX_LENGTH: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "493d7d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 특수 토큰 정의 ===\n",
      "SOS_token: 0\n",
      "EOS_token: 1\n",
      "PAD_token: 2\n",
      "UNK_token: 3\n"
     ]
    }
   ],
   "source": [
    "# 특수 토큰 정의\n",
    "SOS_token = 0  # Start of Sentence\n",
    "EOS_token = 1  # End of Sentence\n",
    "PAD_token = 2  # Padding\n",
    "UNK_token = 3  # Unknown\n",
    "\n",
    "print(\"=== 특수 토큰 정의 ===\")\n",
    "print(f\"SOS_token: {SOS_token}\")\n",
    "print(f\"EOS_token: {EOS_token}\")\n",
    "print(f\"PAD_token: {PAD_token}\")\n",
    "print(f\"UNK_token: {UNK_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f11e29d",
   "metadata": {},
   "source": [
    "# 어휘 사전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64485e64",
   "metadata": {},
   "source": [
    "## Lang 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f029f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lang 클래스 테스트 ===\n",
      "어휘 크기: 6\n",
      "단어-인덱스: {'PAD': 2, 'SOS': 0, 'EOS': 1, '<unk>': 3, '안녕하세요': 4, '반갑습니다': 5}\n",
      "인덱스-단어: {2: 'PAD', 0: 'SOS', 1: 'EOS', 3: '<unk>', 4: '안녕하세요', 5: '반갑습니다'}\n",
      "단어 빈도수: {'PAD': 0, 'SOS': 0, 'EOS': 0, '<unk>': 0, '안녕하세요': 1, '반갑습니다': 1}\n"
     ]
    }
   ],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        # 초기에는 PAD, SOS, EOS, UNK 토큰을 미리 등록\n",
    "        self.word2index = {\"PAD\": PAD_token, \"SOS\": SOS_token, \"EOS\": EOS_token, \"<unk>\": UNK_token}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token: \"<unk>\"}\n",
    "        # word2count도 특수 토큰으로 초기화\n",
    "        self.word2count = {\"PAD\": 0, \"SOS\": 0, \"EOS\": 0, \"<unk>\": 0}\n",
    "        self.n_words = 4  # PAD, SOS, EOS, UNK 포함\n",
    "\n",
    "    def addSentence(self, sentence, tokenizer):\n",
    "        \"\"\"문장을 토큰화하여 어휘 사전에 추가\"\"\"\n",
    "        for word in tokenizer(sentence):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        \"\"\"단어를 어휘 사전에 추가\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        \"\"\"어휘 크기 반환\"\"\"\n",
    "        return self.n_words\n",
    "\n",
    "    def get_word_frequency(self, min_freq=1):\n",
    "        \"\"\"최소 빈도수 이상의 단어만 반환\"\"\"\n",
    "        return {word: count for word, count in self.word2count.items() if count >= min_freq}\n",
    "\n",
    "# Lang 클래스 테스트\n",
    "print(\"=== Lang 클래스 테스트 ===\")\n",
    "test_lang = Lang(\"test\")\n",
    "test_sentence = \"안녕하세요 반갑습니다\"\n",
    "test_lang.addSentence(test_sentence, tokenizer_ko)\n",
    "\n",
    "print(f\"어휘 크기: {test_lang.get_vocab_size()}\")\n",
    "print(f\"단어-인덱스: {test_lang.word2index}\")\n",
    "print(f\"인덱스-단어: {test_lang.index2word}\")\n",
    "print(f\"단어 빈도수: {test_lang.word2count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654968d",
   "metadata": {},
   "source": [
    "## 어휘 사전 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c068ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 어휘 사전 구축 중 ===\n",
      "한국어 문장 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "한국어 처리: 100%|██████████| 10000/10000 [00:07<00:00, 1343.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 문장 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "영어 처리: 100%|██████████| 10000/10000 [00:00<00:00, 33384.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 어휘 통계 ===\n",
      "한국어 어휘 크기: 13774\n",
      "영어 어휘 크기: 9941\n",
      "\n",
      "한국어 상위 10개 단어: [('.', 8520), ('을', 2868), ('이', 2532), ('>', 2398), (',', 2325), ('에', 2082), ('를', 1585), ('의', 1519), ('가', 1481), ('는', 1269)]\n",
      "영어 상위 10개 단어: [('.', 8643), (',', 4518), ('the', 3815), ('to', 2839), ('I', 2490), ('you', 2371), ('a', 2272), ('and', 1850), ('>', 1823), ('it', 1696)]\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, tokenizer1, tokenizer2, min_freq=2):\n",
    "    \"\"\"한국어와 영어 어휘 사전 구축\"\"\"\n",
    "    print(\"=== 어휘 사전 구축 중 ===\")\n",
    "    \n",
    "    input_lang = Lang(lang1)  # 한국어\n",
    "    output_lang = Lang(lang2)  # 영어\n",
    "    \n",
    "    print(\"한국어 문장 처리 중...\")\n",
    "    for sentence in tqdm(ko_sentences_train, desc=\"한국어 처리\"):\n",
    "        input_lang.addSentence(sentence, tokenizer1)\n",
    "    \n",
    "    print(\"영어 문장 처리 중...\")\n",
    "    for sentence in tqdm(mt_sentences_train, desc=\"영어 처리\"):\n",
    "        output_lang.addSentence(sentence, tokenizer2)\n",
    "    \n",
    "    # 최소 빈도수 필터링\n",
    "    print(f\"\\n=== 어휘 통계 ===\")\n",
    "    print(f\"한국어 어휘 크기: {input_lang.get_vocab_size()}\")\n",
    "    print(f\"영어 어휘 크기: {output_lang.get_vocab_size()}\")\n",
    "    \n",
    "    # 빈도수 상위 10개 단어 확인 (특수 토큰 제외)\n",
    "    ko_top_words = [(word, count) for word, count in input_lang.word2count.items() \n",
    "                    if word not in [\"PAD\", \"SOS\", \"EOS\", \"<unk>\"]]\n",
    "    ko_top_words = sorted(ko_top_words, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    en_top_words = [(word, count) for word, count in output_lang.word2count.items() \n",
    "                    if word not in [\"PAD\", \"SOS\", \"EOS\", \"<unk>\"]]\n",
    "    en_top_words = sorted(en_top_words, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    print(f\"\\n한국어 상위 10개 단어: {ko_top_words}\")\n",
    "    print(f\"영어 상위 10개 단어: {en_top_words}\")\n",
    "    \n",
    "    return input_lang, output_lang\n",
    "\n",
    "# 어휘 사전 구축\n",
    "input_lang, output_lang = prepareData(\"한국어\", \"영어\", tokenizer_ko, tokenizer_en, min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e44b1",
   "metadata": {},
   "source": [
    "## 어휘 사전 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a25067f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘 사전 저장 완료: models/korean_vocab.pkl\n",
      "어휘 사전 저장 완료: models/english_vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "# 어휘 사전 저장 (나중에 재사용하기 위해)\n",
    "def save_vocab(lang, filename):\n",
    "    \"\"\"어휘 사전을 파일로 저장\"\"\"\n",
    "    vocab_data = {\n",
    "        'word2index': lang.word2index,\n",
    "        'index2word': lang.index2word,\n",
    "        'word2count': lang.word2count,\n",
    "        'n_words': lang.n_words\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(vocab_data, f)\n",
    "    print(f\"어휘 사전 저장 완료: {filename}\")\n",
    "\n",
    "def load_vocab(filename):\n",
    "    \"\"\"저장된 어휘 사전을 파일에서 로드\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        vocab_data = pickle.load(f)\n",
    "    \n",
    "    lang = Lang(\"loaded\")\n",
    "    lang.word2index = vocab_data['word2index']\n",
    "    lang.index2word = vocab_data['index2word']\n",
    "    lang.word2count = vocab_data['word2count']\n",
    "    lang.n_words = vocab_data['n_words']\n",
    "    \n",
    "    print(f\"어휘 사전 로드 완료: {filename}\")\n",
    "    return lang\n",
    "\n",
    "# 어휘 사전 저장\n",
    "save_vocab(input_lang, \"models/korean_vocab.pkl\")\n",
    "save_vocab(output_lang, \"models/english_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf3d6f",
   "metadata": {},
   "source": [
    "# 데이터 전처리 및 텐서 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12b74a",
   "metadata": {},
   "source": [
    "## s2i, i2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5094164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 변환 함수 테스트 ===\n",
      "원본: 안녕하세요 반갑습니다\n",
      "토큰화: ['안녕하세요', '반갑습니다']\n",
      "인덱스: [0, 211, 5187, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "재구성: 안녕하세요 반갑습니다\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_indexes(sentence, lang, tokenizer, max_length):\n",
    "    \"\"\"문장을 토큰 인덱스로 변환\"\"\"\n",
    "    tokens = tokenizer(sentence)\n",
    "    indexes = [lang.word2index.get(token, UNK_token) for token in tokens]\n",
    "    \n",
    "    # SOS, EOS 토큰 추가\n",
    "    indexes = [SOS_token] + indexes + [EOS_token]\n",
    "    \n",
    "    # 패딩\n",
    "    if len(indexes) < max_length:\n",
    "        indexes += [PAD_token] * (max_length - len(indexes))\n",
    "    else:\n",
    "        indexes = indexes[:max_length-1] + [EOS_token]\n",
    "    \n",
    "    return indexes\n",
    "\n",
    "def indexes_to_sentence(indexes, lang):\n",
    "    \"\"\"인덱스를 문장으로 변환\"\"\"\n",
    "    words = []\n",
    "    for idx in indexes:\n",
    "        if idx == PAD_token:\n",
    "            continue\n",
    "        if idx == EOS_token:\n",
    "            break\n",
    "        if idx in [SOS_token, PAD_token]:\n",
    "            continue\n",
    "        words.append(lang.index2word.get(idx, \"<unk>\"))\n",
    "    return \" \".join(words)\n",
    "\n",
    "# 변환 함수 테스트\n",
    "print(\"=== 변환 함수 테스트 ===\")\n",
    "test_ko = \"안녕하세요 반갑습니다\"\n",
    "test_indexes = sentence_to_indexes(test_ko, input_lang, tokenizer_ko, MAX_LENGTH)\n",
    "test_reconstructed = indexes_to_sentence(test_indexes, input_lang)\n",
    "\n",
    "print(f\"원본: {test_ko}\")\n",
    "print(f\"토큰화: {tokenizer_ko(test_ko)}\")\n",
    "print(f\"인덱스: {test_indexes}\")\n",
    "print(f\"재구성: {test_reconstructed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803c836",
   "metadata": {},
   "source": [
    "## 데이터셋 및 Dataloader 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17158723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 데이터셋 생성 중 ===\n",
      "훈련 데이터셋 크기: 10000\n",
      "검증 데이터셋 크기: 1000\n",
      "\n",
      "=== 데이터셋 테스트 ===\n",
      "샘플 데이터:\n",
      "  한국어 텐서: tensor([ 0,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  1,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2])\n",
      "  영어 텐서: tensor([ 0,  4,  5,  6,  7,  8,  9,  5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "         1,  2,  2,  2,  2,  2,  2])\n",
      "  한국어 길이: 11\n",
      "  영어 길이: 17\n"
     ]
    }
   ],
   "source": [
    "class TranslationDataset:\n",
    "    def __init__(self, ko_sentences, en_sentences, input_lang, output_lang, \n",
    "                 tokenizer_ko, tokenizer_en, max_length):\n",
    "        self.ko_sentences = ko_sentences\n",
    "        self.en_sentences = en_sentences\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.tokenizer_ko = tokenizer_ko\n",
    "        self.tokenizer_en = tokenizer_en\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ko_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ko_sentence = self.ko_sentences[idx]\n",
    "        en_sentence = self.en_sentences[idx]\n",
    "        \n",
    "        # 한국어와 영어 문장을 인덱스로 변환\n",
    "        ko_indexes = sentence_to_indexes(ko_sentence, self.input_lang, \n",
    "                                       self.tokenizer_ko, self.max_length)\n",
    "        en_indexes = sentence_to_indexes(en_sentence, self.output_lang, \n",
    "                                       self.tokenizer_en, self.max_length)\n",
    "        \n",
    "        return {\n",
    "            'ko': torch.tensor(ko_indexes, dtype=torch.long),\n",
    "            'en': torch.tensor(en_indexes, dtype=torch.long),\n",
    "            'ko_length': len(self.tokenizer_ko(ko_sentence)),\n",
    "            'en_length': len(self.tokenizer_en(en_sentence))\n",
    "        }\n",
    "\n",
    "# 데이터셋 생성\n",
    "print(\"=== 데이터셋 생성 중 ===\")\n",
    "train_dataset = TranslationDataset(\n",
    "    ko_sentences_train, mt_sentences_train, \n",
    "    input_lang, output_lang, \n",
    "    tokenizer_ko, tokenizer_en, MAX_LENGTH\n",
    ")\n",
    "\n",
    "valid_dataset = TranslationDataset(\n",
    "    ko_sentences_valid, mt_sentences_valid, \n",
    "    input_lang, output_lang, \n",
    "    tokenizer_ko, tokenizer_en, MAX_LENGTH\n",
    ")\n",
    "\n",
    "print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "print(f\"검증 데이터셋 크기: {len(valid_dataset)}\")\n",
    "\n",
    "# 데이터셋 테스트\n",
    "print(\"\\n=== 데이터셋 테스트 ===\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"샘플 데이터:\")\n",
    "print(f\"  한국어 텐서: {sample['ko']}\")\n",
    "print(f\"  영어 텐서: {sample['en']}\")\n",
    "print(f\"  한국어 길이: {sample['ko_length']}\")\n",
    "print(f\"  영어 길이: {sample['en_length']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82f7a8",
   "metadata": {},
   "source": [
    "## DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce6e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DataLoader 생성 완료 ===\n",
      "훈련 배치 수: 313\n",
      "검증 배치 수: 32\n",
      "\n",
      "=== DataLoader 테스트 ===\n",
      "배치 크기:\n",
      "  한국어: torch.Size([32, 25])\n",
      "  영어: torch.Size([32, 25])\n",
      "  한국어 길이: tensor([ 8, 20,  5, 13,  9])...\n",
      "  영어 길이: tensor([10, 19,  5, 10, 12])...\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 생성\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"배치 데이터를 정리하는 함수\"\"\"\n",
    "    ko = torch.stack([b['ko'] for b in batch])      # [B, S]\n",
    "    en = torch.stack([b['en'] for b in batch])      # [B, T]\n",
    "    ko_raw = torch.tensor([b['ko_length'] for b in batch], dtype=torch.long)\n",
    "    en_raw = torch.tensor([b['en_length'] for b in batch], dtype=torch.long)\n",
    "\n",
    "    # BOS/EOS(+2) 반영 후 실제 시퀀스 길이로 clamp\n",
    "    ko_lengths = torch.clamp(ko_raw + 2, max=ko.size(1))\n",
    "    en_lengths = torch.clamp(en_raw + 2, max=en.size(1))\n",
    "\n",
    "    return {'ko': ko, 'en': en, 'ko_lengths': ko_lengths, 'en_lengths': en_lengths}\n",
    "\n",
    "\n",
    "# 훈련 및 검증 DataLoader 생성\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0  # Windows에서는 0으로 설정\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"=== DataLoader 생성 완료 ===\")\n",
    "print(f\"훈련 배치 수: {len(train_loader)}\")\n",
    "print(f\"검증 배치 수: {len(valid_loader)}\")\n",
    "\n",
    "# DataLoader 테스트\n",
    "print(\"\\n=== DataLoader 테스트 ===\")\n",
    "for batch in train_loader:\n",
    "    print(f\"배치 크기:\")\n",
    "    print(f\"  한국어: {batch['ko'].shape}\")\n",
    "    print(f\"  영어: {batch['en'].shape}\")\n",
    "    print(f\"  한국어 길이: {batch['ko_lengths'][:5]}...\")  # 처음 5개만\n",
    "    print(f\"  영어 길이: {batch['en_lengths'][:5]}...\")    # 처음 5개만\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5358935",
   "metadata": {},
   "source": [
    "# Seq2Seq 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f3edb",
   "metadata": {},
   "source": [
    "## Encoder 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca1eabd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Encoder 테스트 ===\n",
      "입력 크기: torch.Size([2, 10])\n",
      "출력 크기: torch.Size([2, 8, 256])\n",
      "은닉 상태 크기: torch.Size([2, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, num_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size, padding_idx=PAD_token)\n",
    "        \n",
    "        # GRU 레이어\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_size, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # 드롭아웃\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # 임베딩 적용\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        \n",
    "        # PackedSequence로 변환 (패딩 제거)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, input_lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # GRU 순전파\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        # PackedSequence를 다시 일반 텐서로 변환\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "        \n",
    "        return outputs, hidden\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        \"\"\"은닉 상태 초기화\"\"\"\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# Encoder 테스트\n",
    "print(\"=== Encoder 테스트 ===\")\n",
    "encoder = EncoderRNN(\n",
    "    input_size=input_lang.get_vocab_size(),\n",
    "    hidden_size=256,\n",
    "    embedding_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# 테스트 입력\n",
    "test_batch_size = 2\n",
    "test_seq_len = 10\n",
    "test_input = torch.randint(0, 100, (test_batch_size, test_seq_len)).to(device)\n",
    "test_lengths = [8, 6]  # 첫 번째는 길이 8, 두 번째는 길이 6\n",
    "\n",
    "# Encoder 순전파\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    outputs, hidden = encoder(test_input, test_lengths)\n",
    "    \n",
    "print(f\"입력 크기: {test_input.shape}\")\n",
    "print(f\"출력 크기: {outputs.shape}\")\n",
    "print(f\"은닉 상태 크기: {hidden.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd7dd14",
   "metadata": {},
   "source": [
    "## Attention Decoder 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b69429c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d854193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, num_layers=1, dropout=0.1, pad_idx=None, device=\"cpu\"):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "        # 임베딩\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size, padding_idx=pad_idx)\n",
    "\n",
    "        # Attention 레이어들\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "        self.attention_combine = nn.Linear(embedding_size + hidden_size, hidden_size)\n",
    "\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "        # 출력층\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_seq, hidden, encoder_outputs):\n",
    "        B = input_seq.size(0)\n",
    "        \n",
    "        # 1) 임베딩\n",
    "        embedded = self.dropout(self.embedding(input_seq))  # (B,1,E)\n",
    "        \n",
    "        # 2) Attention 가중치 계산 - 수정된 버전\n",
    "        attention_scores = self.calculate_attention(hidden, encoder_outputs)  # (B,S)\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (B,S)\n",
    "        \n",
    "        # 3) Context vector 계산\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)  # (B,1,H)\n",
    "        \n",
    "        # 4) 임베딩과 컨텍스트 결합\n",
    "        gru_input = torch.cat((embedded, context), dim=2)  # (B,1,E+H)\n",
    "        gru_input = self.attention_combine(gru_input)      # (B,1,H)\n",
    "        \n",
    "        # 5) GRU 진행\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        \n",
    "        # 6) 어휘 분포\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden, attention_weights.unsqueeze(1)\n",
    "\n",
    "    def calculate_attention(self, hidden, encoder_outputs):\n",
    "        \"\"\"수정된 Attention 계산\"\"\"\n",
    "        B, S, H = encoder_outputs.size()\n",
    "        \n",
    "        # hidden의 마지막 레이어만 사용\n",
    "        if hidden.dim() == 3:  # (num_layers, B, H)\n",
    "            dec_h_t = hidden[-1]  # (B,H)\n",
    "        else:  # (B, H)\n",
    "            dec_h_t = hidden\n",
    "            \n",
    "        # Attention 스코어 계산\n",
    "        dec_h_expanded = dec_h_t.unsqueeze(1).expand(-1, S, -1)  # (B,S,H)\n",
    "        concat_input = torch.cat([dec_h_expanded, encoder_outputs], dim=2)  # (B,S,2H)\n",
    "        scores = self.attention(concat_input).squeeze(-1)  # (B,S)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7208ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Attention Decoder 재생성 (최종 수정된 버전) ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Attention Decoder 재생성 (최종 수정된 버전) ===\")\n",
    "decoder = AttentionDecoderRNN(\n",
    "    hidden_size=256,\n",
    "    output_size=output_lang.get_vocab_size(),\n",
    "    embedding_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    pad_idx=PAD_token,\n",
    "    device=device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e55e6",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af3202b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, ko_input, ko_lengths, en_input, teacher_forcing_ratio=0.5):\n",
    "        batch_size = ko_input.size(0)\n",
    "        max_length = en_input.size(1)\n",
    "        vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # 인코더 순전파\n",
    "        encoder_outputs, encoder_hidden = self.encoder(ko_input, ko_lengths)\n",
    "        \n",
    "        # 디코더 초기화\n",
    "        decoder_input = torch.full((batch_size, 1), SOS_token, dtype=torch.long, device=self.device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        # 출력 저장용\n",
    "        outputs = torch.zeros(batch_size, max_length, vocab_size, device=self.device)\n",
    "        \n",
    "        # Teacher Forcing 적용\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        for t in range(max_length):\n",
    "            # 디코더 순전파\n",
    "            output, decoder_hidden, attention = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            # 출력 저장\n",
    "            outputs[:, t, :] = output[:, 0, :]\n",
    "            \n",
    "            # Teacher Forcing 비율을 점진적으로 감소\n",
    "            if use_teacher_forcing and t < max_length - 1:\n",
    "                decoder_input = en_input[:, t:t+1]\n",
    "            else:\n",
    "                top1 = output[:, 0, :].argmax(1)\n",
    "                decoder_input = top1.unsqueeze(1)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, ko_input, ko_lengths, max_length=50):\n",
    "        \"\"\"추론 시 사용하는 함수\"\"\"\n",
    "        batch_size = ko_input.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "        \n",
    "        # 인코더 순전파\n",
    "        encoder_outputs, encoder_hidden = self.encoder(ko_input, ko_lengths)\n",
    "        \n",
    "        # 디코더 초기화\n",
    "        decoder_input = torch.full((batch_size, 1), SOS_token, dtype=torch.long, device=self.device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        # 출력 저장용\n",
    "        outputs = torch.zeros(batch_size, max_length, vocab_size, device=self.device)\n",
    "        predicted_indices = torch.zeros(batch_size, max_length, dtype=torch.long, device=self.device)\n",
    "        \n",
    "        for t in range(max_length):\n",
    "            # 디코더 순전파\n",
    "            output, decoder_hidden, attention = self.decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            # 출력 저장\n",
    "            outputs[:, t, :] = output[:, 0, :]\n",
    "            \n",
    "            # 다음 토큰 예측\n",
    "            top1 = output[:, 0, :].argmax(1)\n",
    "            predicted_indices[:, t] = top1\n",
    "            decoder_input = top1.unsqueeze(1)\n",
    "            \n",
    "            # EOS 토큰이 나오면 중단\n",
    "            if (top1 == EOS_token).all():\n",
    "                break\n",
    "        \n",
    "        return predicted_indices, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b45db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model):\n",
    "    \"\"\"모델 가중치 초기화\"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "        elif 'bias' in name:\n",
    "            nn.init.constant_(param, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39b32f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Seq2Seq 모델 생성 ===\n",
      "모델 파라미터 수:\n",
      "  총 파라미터: 7,170,134\n",
      "  학습 가능한 파라미터: 7,170,134\n"
     ]
    }
   ],
   "source": [
    "# Seq2Seq 모델 생성\n",
    "print(\"=== Seq2Seq 모델 생성 ===\")\n",
    "#seq2seq_model = Seq2SeqModel(encoder, decoder, device).to(device)\n",
    "seq2seq_model = Seq2SeqModel(encoder, decoder, device).to(device)\n",
    "init_weights(seq2seq_model)\n",
    "\n",
    "print(f\"모델 파라미터 수:\")\n",
    "total_params = sum(p.numel() for p in seq2seq_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in seq2seq_model.parameters() if p.requires_grad)\n",
    "print(f\"  총 파라미터: {total_params:,}\")\n",
    "print(f\"  학습 가능한 파라미터: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775df18d",
   "metadata": {},
   "source": [
    "## 손실 함수 및 옵티마이저 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b2edca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 학습 설정 완료 ===\n",
      "손실 함수: CrossEntropyLoss()\n",
      "옵티마이저: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "학습률: 0.001\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
    "optimizer = optim.Adam(seq2seq_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# 학습률 스케줄러\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "\n",
    "# Teacher Forcing 비율을 점진적으로 감소\n",
    "def get_teacher_forcing_ratio(epoch, max_epochs):\n",
    "    \"\"\"에포치에 따라 Teacher Forcing 비율을 점진적으로 감소\"\"\"\n",
    "    start_ratio = 0.9\n",
    "    end_ratio = 0.1\n",
    "    decay_rate = (start_ratio - end_ratio) / max_epochs\n",
    "    return max(start_ratio - decay_rate * epoch, end_ratio)\n",
    "\n",
    "\n",
    "print(\"=== 학습 설정 완료 ===\")\n",
    "print(f\"손실 함수: {criterion}\")\n",
    "print(f\"옵티마이저: {optimizer}\")\n",
    "print(f\"학습률: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4500c01",
   "metadata": {},
   "source": [
    "## 학습 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fead5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, teacher_forcing_ratio=0.5):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        # 데이터를 디바이스로 이동\n",
    "        ko_input = batch['ko'].to(device)\n",
    "        en_input = batch['en'].to(device)\n",
    "        ko_lengths = batch['ko_lengths']\n",
    "        en_lengths = batch['en_lengths']\n",
    "        \n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파\n",
    "        outputs = model(ko_input, ko_lengths, en_input, teacher_forcing_ratio)\n",
    "        \n",
    "        # 손실 계산 - PAD 토큰 제외\n",
    "        batch_size, seq_len, vocab_size = outputs.size()\n",
    "        \n",
    "        # PAD 토큰이 아닌 위치만 마스킹\n",
    "        mask = (en_input != PAD_token).float()  # (B,S)\n",
    "        \n",
    "        # 마스킹된 손실 계산\n",
    "        outputs_flat = outputs.view(-1, vocab_size)\n",
    "        targets_flat = en_input.view(-1)\n",
    "        mask_flat = mask.view(-1)\n",
    "        \n",
    "        # PAD가 아닌 위치만 손실 계산\n",
    "        valid_positions = mask_flat > 0\n",
    "        if valid_positions.sum() > 0:\n",
    "            loss = criterion(\n",
    "                outputs_flat[valid_positions], \n",
    "                targets_flat[valid_positions]\n",
    "            )\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "        \n",
    "        \n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 손실 누적\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 진행률 업데이트\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Avg Loss': f'{total_loss/(batch_idx+1):.4f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            # 데이터를 디바이스로 이동\n",
    "            ko_input = batch['ko'].to(device)\n",
    "            en_input = batch['en'].to(device)\n",
    "            ko_lengths = batch['ko_lengths']\n",
    "            en_lengths = batch['en_lengths']\n",
    "            \n",
    "            # 순전파 (Teacher Forcing 없음)\n",
    "            outputs = model(ko_input, ko_lengths, en_input, teacher_forcing_ratio=0.0)\n",
    "            \n",
    "            # 손실 계산 - PAD 토큰 제외\n",
    "            batch_size, seq_len, vocab_size = outputs.size()\n",
    "            \n",
    "            # PAD 토큰이 아닌 위치만 마스킹\n",
    "            mask = (en_input != PAD_token).float()  # (B,S)\n",
    "            \n",
    "            # 마스킹된 손실 계산\n",
    "            outputs_flat = outputs.view(-1, vocab_size)\n",
    "            targets_flat = en_input.view(-1)\n",
    "            mask_flat = mask.view(-1)\n",
    "            \n",
    "            # PAD가 아닌 위치만 손실 계산\n",
    "            valid_positions = mask_flat > 0\n",
    "            if valid_positions.sum() > 0:\n",
    "                loss = criterion(\n",
    "                    outputs_flat[valid_positions], \n",
    "                    targets_flat[valid_positions]\n",
    "                )\n",
    "            else:\n",
    "                loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "            \n",
    "            # 손실 누적\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 진행률 업데이트\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Avg Loss': f'{total_loss/(batch_idx+1):.4f}'\n",
    "            })\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197ffcd",
   "metadata": {},
   "source": [
    "## 번역 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a500277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, input_lang, output_lang, tokenizer_ko, tokenizer_en, max_length=50):\n",
    "    \"\"\"단일 문장 번역\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 한국어 문장을 인덱스로 변환\n",
    "    ko_indexes = sentence_to_indexes(sentence, input_lang, tokenizer_ko, max_length)\n",
    "    ko_tensor = torch.tensor(ko_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    ko_lengths = [len(tokenizer_ko(sentence))]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 번역 수행\n",
    "        predicted_indices, _ = model.predict(ko_tensor, ko_lengths, max_length)\n",
    "        \n",
    "        # 결과를 문장으로 변환\n",
    "        translated_sentence = indexes_to_sentence(predicted_indices[0].cpu().numpy(), output_lang)\n",
    "    \n",
    "    return translated_sentence\n",
    "\n",
    "def evaluate_translations(model, test_sentences, input_lang, output_lang, tokenizer_ko, tokenizer_en):\n",
    "    \"\"\"번역 결과 평가\"\"\"\n",
    "    print(\"=== 번역 결과 평가 ===\")\n",
    "    \n",
    "    for i, ko_sentence in enumerate(test_sentences[:5]):  # 처음 5개만 테스트\n",
    "        print(f\"\\n예시 {i+1}:\")\n",
    "        print(f\"  한국어: {ko_sentence}\")\n",
    "        \n",
    "        # 번역 수행\n",
    "        translated = translate_sentence(\n",
    "            model, ko_sentence, input_lang, output_lang, \n",
    "            tokenizer_ko, tokenizer_en\n",
    "        )\n",
    "        print(f\"  영어: {translated}\")\n",
    "        \n",
    "        # 정답 확인\n",
    "        if i < len(mt_sentences_train):\n",
    "            print(f\"  정답: {mt_sentences_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e99954",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f9b4ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 모델 학습 시작 ===\n",
      "총 에포크: 20\n",
      "체크포인트 저장 간격: 5 에포크\n",
      "\n",
      "=== Epoch 1/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:37<00:00,  3.20it/s, Loss=5.3101, Avg Loss=5.8304]\n",
      "Validation: 100%|██████████| 32/32 [00:04<00:00,  7.04it/s, Loss=5.3864, Avg Loss=5.6769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 결과:\n",
      "  훈련 손실: 5.8304\n",
      "  검증 손실: 5.6769\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 2/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:40<00:00,  3.11it/s, Loss=4.9120, Avg Loss=5.1320]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  9.05it/s, Loss=5.3134, Avg Loss=5.7657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 결과:\n",
      "  훈련 손실: 5.1320\n",
      "  검증 손실: 5.7657\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 3/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:42<00:00,  3.07it/s, Loss=4.6551, Avg Loss=4.8618]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  9.05it/s, Loss=5.1591, Avg Loss=5.3963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 결과:\n",
      "  훈련 손실: 4.8618\n",
      "  검증 손실: 5.3963\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 4/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:42<00:00,  3.06it/s, Loss=5.0303, Avg Loss=4.5500]\n",
      "Validation: 100%|██████████| 32/32 [00:05<00:00,  6.34it/s, Loss=5.1478, Avg Loss=5.3502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 결과:\n",
      "  훈련 손실: 4.5500\n",
      "  검증 손실: 5.3502\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 5/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:46<00:00,  2.94it/s, Loss=4.2478, Avg Loss=4.3755]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.67it/s, Loss=4.9243, Avg Loss=5.2923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 결과:\n",
      "  훈련 손실: 4.3755\n",
      "  검증 손실: 5.2923\n",
      "  학습률: 0.001000\n",
      "  체크포인트 저장: epoch_5.pth\n",
      "\n",
      "  번역 결과 확인:\n",
      "=== 번역 결과 평가 ===\n",
      "\n",
      "예시 1:\n",
      "  한국어: 원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.\n",
      "  영어: It 's a good of the company of the company of the company .\n",
      "  정답: If you reply to the color you want, we will start making it right away.\n",
      "\n",
      "예시 2:\n",
      "  한국어: 형님 제일 웃긴 그림이 뭔지 알아요.\n",
      "  영어: It 's why it 's a , , , .\n",
      "  정답: I know what the funniest picture is.\n",
      "\n",
      "예시 3:\n",
      "  한국어: >속옷을?\n",
      "  영어: > Wow~\n",
      "  정답: Underwear?\n",
      "\n",
      "=== Epoch 6/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:45<00:00,  2.98it/s, Loss=3.8367, Avg Loss=4.2510]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.97it/s, Loss=5.0177, Avg Loss=5.2720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 결과:\n",
      "  훈련 손실: 4.2510\n",
      "  검증 손실: 5.2720\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 7/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:30<00:00,  3.46it/s, Loss=4.6875, Avg Loss=4.0855]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.39it/s, Loss=5.1091, Avg Loss=5.3248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 결과:\n",
      "  훈련 손실: 4.0855\n",
      "  검증 손실: 5.3248\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 8/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:31<00:00,  3.42it/s, Loss=4.7428, Avg Loss=4.0327]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  9.22it/s, Loss=5.2099, Avg Loss=5.2567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 결과:\n",
      "  훈련 손실: 4.0327\n",
      "  검증 손실: 5.2567\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 9/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:31<00:00,  3.43it/s, Loss=4.5935, Avg Loss=3.9289]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  9.04it/s, Loss=5.1759, Avg Loss=5.2757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 결과:\n",
      "  훈련 손실: 3.9289\n",
      "  검증 손실: 5.2757\n",
      "  학습률: 0.001000\n",
      "\n",
      "=== Epoch 10/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:31<00:00,  3.42it/s, Loss=3.4670, Avg Loss=3.8632]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  9.54it/s, Loss=4.9533, Avg Loss=5.2603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 결과:\n",
      "  훈련 손실: 3.8632\n",
      "  검증 손실: 5.2603\n",
      "  학습률: 0.000500\n",
      "  체크포인트 저장: epoch_10.pth\n",
      "\n",
      "  번역 결과 확인:\n",
      "=== 번역 결과 평가 ===\n",
      "\n",
      "예시 1:\n",
      "  한국어: 원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.\n",
      "  영어: If you have any questions , please contact you the email you to be\n",
      "  정답: If you reply to the color you want, we will start making it right away.\n",
      "\n",
      "예시 2:\n",
      "  한국어: 형님 제일 웃긴 그림이 뭔지 알아요.\n",
      "  영어: How you you you ?\n",
      "  정답: I know what the funniest picture is.\n",
      "\n",
      "예시 3:\n",
      "  한국어: >속옷을?\n",
      "  영어: > Wow~\n",
      "  정답: Underwear?\n",
      "\n",
      "=== Epoch 11/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:36<00:00,  3.24it/s, Loss=2.8547, Avg Loss=3.7514]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.39it/s, Loss=4.7043, Avg Loss=5.2313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 결과:\n",
      "  훈련 손실: 3.7514\n",
      "  검증 손실: 5.2313\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 12/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:49<00:00,  2.86it/s, Loss=3.7952, Avg Loss=3.6352]\n",
      "Validation: 100%|██████████| 32/32 [00:04<00:00,  7.29it/s, Loss=4.8069, Avg Loss=5.2580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 결과:\n",
      "  훈련 손실: 3.6352\n",
      "  검증 손실: 5.2580\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 13/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:57<00:00,  2.66it/s, Loss=2.8126, Avg Loss=3.5806]\n",
      "Validation: 100%|██████████| 32/32 [00:04<00:00,  7.66it/s, Loss=5.0422, Avg Loss=5.3268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 결과:\n",
      "  훈련 손실: 3.5806\n",
      "  검증 손실: 5.3268\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 14/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:43<00:00,  3.02it/s, Loss=4.0426, Avg Loss=3.5434]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.43it/s, Loss=4.7955, Avg Loss=5.2964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 결과:\n",
      "  훈련 손실: 3.5434\n",
      "  검증 손실: 5.2964\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 15/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:56<00:00,  2.69it/s, Loss=3.9936, Avg Loss=3.5778]\n",
      "Validation: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s, Loss=4.9367, Avg Loss=5.3438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 결과:\n",
      "  훈련 손실: 3.5778\n",
      "  검증 손실: 5.3438\n",
      "  학습률: 0.000500\n",
      "  체크포인트 저장: epoch_15.pth\n",
      "\n",
      "  번역 결과 확인:\n",
      "=== 번역 결과 평가 ===\n",
      "\n",
      "예시 1:\n",
      "  한국어: 원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.\n",
      "  영어: If you have any questions , please , please the the the contact the . .\n",
      "  정답: If you reply to the color you want, we will start making it right away.\n",
      "\n",
      "예시 2:\n",
      "  한국어: 형님 제일 웃긴 그림이 뭔지 알아요.\n",
      "  영어: What you I do you ? ?\n",
      "  정답: I know what the funniest picture is.\n",
      "\n",
      "예시 3:\n",
      "  한국어: >속옷을?\n",
      "  영어: Woah~\n",
      "  정답: Underwear?\n",
      "\n",
      "=== Epoch 16/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:43<00:00,  3.01it/s, Loss=4.1106, Avg Loss=3.5831]\n",
      "Validation: 100%|██████████| 32/32 [00:04<00:00,  7.99it/s, Loss=4.9888, Avg Loss=5.3709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 결과:\n",
      "  훈련 손실: 3.5831\n",
      "  검증 손실: 5.3709\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 17/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:38<00:00,  3.17it/s, Loss=3.5090, Avg Loss=3.5342]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.00it/s, Loss=4.9249, Avg Loss=5.3872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 결과:\n",
      "  훈련 손실: 3.5342\n",
      "  검증 손실: 5.3872\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 18/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:36<00:00,  3.23it/s, Loss=2.6463, Avg Loss=3.4907]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.52it/s, Loss=4.8821, Avg Loss=5.3561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 결과:\n",
      "  훈련 손실: 3.4907\n",
      "  검증 손실: 5.3561\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 19/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:34<00:00,  3.32it/s, Loss=3.7319, Avg Loss=3.5377]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.38it/s, Loss=5.0955, Avg Loss=5.4363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 결과:\n",
      "  훈련 손실: 3.5377\n",
      "  검증 손실: 5.4363\n",
      "  학습률: 0.000500\n",
      "\n",
      "=== Epoch 20/20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 313/313 [01:35<00:00,  3.28it/s, Loss=3.6243, Avg Loss=3.4679]\n",
      "Validation: 100%|██████████| 32/32 [00:03<00:00,  8.77it/s, Loss=4.9524, Avg Loss=5.4185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 결과:\n",
      "  훈련 손실: 3.4679\n",
      "  검증 손실: 5.4185\n",
      "  학습률: 0.000250\n",
      "  체크포인트 저장: epoch_20.pth\n",
      "\n",
      "  번역 결과 확인:\n",
      "=== 번역 결과 평가 ===\n",
      "\n",
      "예시 1:\n",
      "  한국어: 원하시는 색상을 회신해 주시면 바로 제작 들어가겠습니다.\n",
      "  영어: If you have to the the , , to to to to to the the . .\n",
      "  정답: If you reply to the color you want, we will start making it right away.\n",
      "\n",
      "예시 2:\n",
      "  한국어: 형님 제일 웃긴 그림이 뭔지 알아요.\n",
      "  영어: What 's you , you you ? ?\n",
      "  정답: I know what the funniest picture is.\n",
      "\n",
      "예시 3:\n",
      "  한국어: >속옷을?\n",
      "  영어: Rock-paper-scissors .\n",
      "  정답: Underwear?\n",
      "\n",
      "=== 모델 학습 완료 ===\n"
     ]
    }
   ],
   "source": [
    "# 학습 파라미터 설정\n",
    "EPOCHS = 20\n",
    "SAVE_INTERVAL = 5\n",
    "\n",
    "# 학습 및 검증 손실 저장\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "print(\"=== 모델 학습 시작 ===\")\n",
    "print(f\"총 에포크: {EPOCHS}\")\n",
    "print(f\"체크포인트 저장 간격: {SAVE_INTERVAL} 에포크\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n=== Epoch {epoch+1}/{EPOCHS} ===\")\n",
    "    \n",
    "    # 학습\n",
    "    teacher_forcing_ratio = get_teacher_forcing_ratio(epoch, EPOCHS)\n",
    "    train_loss = train_epoch(seq2seq_model, train_loader, criterion, optimizer, device, teacher_forcing_ratio)\n",
    "    #train_loss = train_epoch(seq2seq_model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # 검증\n",
    "    valid_loss = validate_epoch(seq2seq_model, valid_loader, criterion, device)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # 학습률 조정\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} 결과:\")\n",
    "    print(f\"  훈련 손실: {train_loss:.4f}\")\n",
    "    print(f\"  검증 손실: {valid_loss:.4f}\")\n",
    "    print(f\"  학습률: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # 체크포인트 저장\n",
    "    if (epoch + 1) % SAVE_INTERVAL == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': seq2seq_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'valid_loss': valid_loss,\n",
    "            'train_losses': train_losses,\n",
    "            'valid_losses': valid_losses\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, f\"checkpoints/seq2seq_attention_epoch_{epoch+1}.pth\")\n",
    "        print(f\"  체크포인트 저장: epoch_{epoch+1}.pth\")\n",
    "    \n",
    "    # 번역 결과 확인 (5에포크마다)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(\"\\n  번역 결과 확인:\")\n",
    "        test_sentences = ko_sentences_train[:3]  # 처음 3개 문장으로 테스트\n",
    "        evaluate_translations(\n",
    "            seq2seq_model, test_sentences, input_lang, output_lang, \n",
    "            tokenizer_ko, tokenizer_en\n",
    "        )\n",
    "\n",
    "print(\"\\n=== 모델 학습 완료 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a717c",
   "metadata": {},
   "source": [
    "## 번역 품질 평가 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c300575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 완료 후 번역 품질 평가\n",
    "def comprehensive_evaluation():\n",
    "    print(\"=== 종합 번역 품질 평가 ===\")\n",
    "    \n",
    "    # 1. 샘플 번역 결과\n",
    "    test_sentences = ko_sentences_train[:10]\n",
    "    evaluate_translations(seq2seq_model, test_sentences, input_lang, output_lang, tokenizer_ko, tokenizer_en)\n",
    "    \n",
    "    # 2. BLEU 점수 계산 (간단한 구현)\n",
    "    bleu_score = calculate_simple_bleu()\n",
    "    print(f\"BLEU Score: {bleu_score:.2f}\")\n",
    "    \n",
    "    # 3. Attention 가중치 시각화\n",
    "    visualize_attention_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_3 (conda)",
   "language": "python",
   "name": "ai_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
