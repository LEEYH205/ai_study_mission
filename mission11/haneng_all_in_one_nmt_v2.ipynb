{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c32a74",
   "metadata": {},
   "source": [
    "\n",
    "# 🇰🇷→🇺🇸 NMT All-in-One — Seq2Seq + Attention(Bahdanau/Luong) + BLEU/chrF + TF Schedule + SPM Fallback + Sampling Curves\n",
    "\n",
    "이 노트북은 스프린트 미션 요구를 한 번에 수행합니다.\n",
    "- Tokenizer: SentencePiece(설치 시) / Whitespace 폴백\n",
    "- Length EDA: 퍼센타일 기반 자동 MAX_LEN\n",
    "- Models: Seq2Seq(GRU), Bahdanau(Additive), Luong(General)\n",
    "- Training: Teacher Forcing ratio 로그 또는 Scheduled Sampling\n",
    "- Metrics: BLEU/chrF (sacrebleu), 랜덤 샘플 출력\n",
    "- Experiments: SAMPLE_SIZES 별 학습 곡선 & 결과 CSV 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d08b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "CONFIG = {\n",
    "    \"train_json\": \"data/일상생활및구어체_한영_train_set.json\",\n",
    "    \"valid_json\": \"data/일상생활및구어체_한영_valid_set.json\",\n",
    "    \"use_sentencepiece\": True,\n",
    "    \"spm_vocab_ko\": 8000,\n",
    "    \"spm_vocab_en\": 8000,\n",
    "    \"attention\": \"bahdanau\",      # \"none\" | \"bahdanau\" | \"luong\"\n",
    "    \"src_max_len\": 64,\n",
    "    \"tgt_max_len\": 64,\n",
    "    \"batch_size\": 128,\n",
    "    \"emb\": 256,\n",
    "    \"enc_hid\": 256,\n",
    "    \"dec_hid\": 256,\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 2e-3,\n",
    "    \"tf_mode\": \"log_only\",        # \"log_only\" | \"scheduled\"\n",
    "    \"tf_start\": 1.0,\n",
    "    \"tf_end\": 0.5,\n",
    "    \"sample_sizes\": [100, 500, 1000, 2000],\n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "CONFIG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Imports & Seed\n",
    "# =====================\n",
    "import os, json, math, random, re, glob\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import sacrebleu\n",
    "    HAS_SACREBLEU = True\n",
    "except Exception:\n",
    "    HAS_SACREBLEU = False\n",
    "\n",
    "try:\n",
    "    import sentencepiece as spm\n",
    "    HAS_SPM = True\n",
    "except Exception:\n",
    "    HAS_SPM = False\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "CONFIG[\"device\"] = \"cuda\" if (CONFIG[\"device\"]==\"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
    "Path(\"spm\").mkdir(exist_ok=True); Path(\"data\").mkdir(exist_ok=True); Path(\"curves\").mkdir(exist_ok=True)\n",
    "print(\"[DIAG] device:\", CONFIG[\"device\"], \"| HAS_SPM:\", HAS_SPM, \"| HAS_SACREBLEU:\", HAS_SACREBLEU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Data Utils\n",
    "# =====================\n",
    "def basic_clean(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \" \", s.strip())\n",
    "    return s\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def ensure_data(train_path, valid_path):\n",
    "    tp, vp = Path(train_path), Path(valid_path)\n",
    "    if tp.exists() and vp.exists():\n",
    "        return load_json(train_path), load_json(valid_path)\n",
    "    print(\"[INFO] 데이터 파일 없음: 토이 데이터 생성\")\n",
    "    toy_pairs = [\n",
    "        {\"ko\": \"안녕하세요\", \"mt\": \"Hello\"},\n",
    "        {\"ko\": \"오늘 날씨 어때요?\", \"mt\": \"How is the weather today?\"},\n",
    "        {\"ko\": \"이름이 뭐예요?\", \"mt\": \"What is your name?\"},\n",
    "        {\"ko\": \"고마워요\", \"mt\": \"Thank you\"},\n",
    "        {\"ko\": \"지금 몇 시예요?\", \"mt\": \"What time is it now?\"},\n",
    "        {\"ko\": \"커피 좋아해요\", \"mt\": \"I like coffee\"},\n",
    "        {\"ko\": \"어디 가세요?\", \"mt\": \"Where are you going?\"},\n",
    "        {\"ko\": \"배고파요\", \"mt\": \"I am hungry\"},\n",
    "        {\"ko\": \"내일 만나요\", \"mt\": \"See you tomorrow\"},\n",
    "        {\"ko\": \"잘 자요\", \"mt\": \"Good night\"}\n",
    "    ]\n",
    "    train, valid = toy_pairs[:8], toy_pairs[8:]\n",
    "    with open(train_path, \"w\", encoding=\"utf-8\") as f: json.dump(train, f, ensure_ascii=False, indent=2)\n",
    "    with open(valid_path, \"w\", encoding=\"utf-8\") as f: json.dump(valid, f, ensure_ascii=False, indent=2)\n",
    "    return train, valid\n",
    "\n",
    "train_pairs_full, valid_pairs_full = ensure_data(CONFIG[\"train_json\"], CONFIG[\"valid_json\"])\n",
    "len(train_pairs_full), len(valid_pairs_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Tokenizer (SPM or Whitespace)\n",
    "# =====================\n",
    "SPECIAL_TOKENS = {\"UNK\":0, \"BOS\":1, \"EOS\":2, \"PAD\":3}\n",
    "UNK, BOS, EOS, PAD = 0, 1, 2, 3\n",
    "\n",
    "class WhitespaceTokenizer:\n",
    "    def __init__(self, texts, vocab_size=8000):\n",
    "        from collections import Counter\n",
    "        freq = Counter()\n",
    "        for t in texts: freq.update(basic_clean(t).split())\n",
    "        most = [w for w,_ in freq.most_common(max(0, vocab_size-4))]\n",
    "        self.itos = [\"<unk>\",\"<bos>\",\"<eos>\",\"<pad>\"] + most\n",
    "        self.stoi = {w:i for i,w in enumerate(self.itos)}\n",
    "    def encode(self, text): return [self.stoi.get(t, UNK) for t in basic_clean(text).split()]\n",
    "    def decode(self, ids):\n",
    "        return \" \".join(self.itos[i] if 0<=i<len(self.itos) and i not in (BOS,EOS,PAD) else \"\" for i in ids).strip()\n",
    "    def vocab_size(self): return len(self.itos)\n",
    "\n",
    "class SentencePieceTokenizer:\n",
    "    def __init__(self, corpus_path, model_prefix, vocab_size=8000, coverage=0.9995):\n",
    "        if not Path(model_prefix+\".model\").exists():\n",
    "            print(f\"[SPM] training {model_prefix} (vocab={vocab_size}) ...\")\n",
    "            spm.SentencePieceTrainer.train(\n",
    "                input=corpus_path, model_prefix=model_prefix, vocab_size=vocab_size,\n",
    "                model_type=\"unigram\", character_coverage=coverage,\n",
    "                input_sentence_size=200000, shuffle_input_sentence=True,\n",
    "                hard_vocab_limit=False, train_extremely_large_corpus=False,\n",
    "                unk_id=UNK, bos_id=BOS, eos_id=EOS, pad_id=PAD\n",
    "            )\n",
    "            print(f\"[SPM] done: {model_prefix}.model\")\n",
    "        self.sp = spm.SentencePieceProcessor(); self.sp.load(model_prefix + \".model\")\n",
    "    def encode(self, text): return list(self.sp.encode(text, out_type=int))\n",
    "    def decode(self, ids): return self.sp.decode(ids)\n",
    "    def vocab_size(self): return self.sp.get_piece_size()\n",
    "\n",
    "def build_tokenizers(pairs_train):\n",
    "    all_ko = [basic_clean(x[\"ko\"]) for x in pairs_train]\n",
    "    all_en = [basic_clean(x[\"mt\"]) for x in pairs_train]\n",
    "    Path(\"spm\").mkdir(exist_ok=True)\n",
    "    if CONFIG[\"use_sentencepiece\"] and HAS_SPM:\n",
    "        with open(\"spm/corpus.ko.txt\",\"w\",encoding=\"utf-8\") as f: f.write(\"\\n\".join(all_ko))\n",
    "        with open(\"spm/corpus.en.txt\",\"w\",encoding=\"utf-8\") as f: f.write(\"\\n\".join(all_en))\n",
    "        print(\"[Tokenizer] SentencePiece mode\")\n",
    "        tok_ko = SentencePieceTokenizer(\"spm/corpus.ko.txt\", \"spm/ko\", CONFIG[\"spm_vocab_ko\"], coverage=0.9995)\n",
    "        tok_en = SentencePieceTokenizer(\"spm/corpus.en.txt\", \"spm/en\", CONFIG[\"spm_vocab_en\"], coverage=1.0)\n",
    "    else:\n",
    "        print(\"[Tokenizer] Whitespace mode\")\n",
    "        tok_ko = WhitespaceTokenizer(all_ko, CONFIG[\"spm_vocab_ko\"])\n",
    "        tok_en = WhitespaceTokenizer(all_en, CONFIG[\"spm_vocab_en\"])\n",
    "    print(f\"[Tokenizer] koV={tok_ko.vocab_size()} enV={tok_en.vocab_size()}\")\n",
    "    return tok_ko, tok_en\n",
    "\n",
    "print(\"[INFO] Building tokenizers ...\")\n",
    "tok_ko, tok_en = build_tokenizers(train_pairs_full)\n",
    "print(\"[INFO] Tokenizers ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Length EDA → AUTO MAX_LEN (P95)\n",
    "# =====================\n",
    "import numpy as np\n",
    "\n",
    "def _len_with_bos_eos(texts, tok):\n",
    "    return [len([BOS] + tok.encode(s) + [EOS]) for s in texts]\n",
    "\n",
    "src_lens = np.array(_len_with_bos_eos([x[\"ko\"] for x in train_pairs_full], tok_ko))\n",
    "tgt_lens = np.array(_len_with_bos_eos([x[\"mt\"] for x in train_pairs_full], tok_en))\n",
    "\n",
    "CONFIG[\"src_max_len\"] = int(np.percentile(src_lens, 95))\n",
    "CONFIG[\"tgt_max_len\"] = int(np.percentile(tgt_lens, 95))\n",
    "print(\"AUTO MAX_LEN:\", CONFIG[\"src_max_len\"], CONFIG[\"tgt_max_len\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Dataset / Collate\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, pairs, tok_ko, tok_en, src_max, tgt_max):\n",
    "        self.pairs = pairs; self.tok_ko = tok_ko; self.tok_en = tok_en\n",
    "        self.src_max = src_max; self.tgt_max = tgt_max\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        ko = basic_clean(self.pairs[i][\"ko\"]); en = basic_clean(self.pairs[i][\"mt\"])\n",
    "        src_ids = [BOS] + self.tok_ko.encode(ko) + [EOS]\n",
    "        tgt_ids = [BOS] + self.tok_en.encode(en) + [EOS]\n",
    "        src_ids = src_ids[:self.src_max]; tgt_ids = tgt_ids[:self.tgt_max]\n",
    "        ko_raw = max(0, len(src_ids)-2); en_raw = max(0, len(tgt_ids)-2)\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids), ko_raw, en_raw\n",
    "\n",
    "def pad_sequences(seqs, pad=PAD):\n",
    "    maxlen = max(s.size(0) for s in seqs)\n",
    "    out = torch.full((len(seqs), maxlen), pad, dtype=torch.long)\n",
    "    for i, s in enumerate(seqs): out[i, :s.size(0)] = s\n",
    "    return out\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, tgts, ko_raws, en_raws = zip(*batch)\n",
    "    src = pad_sequences(srcs, pad=PAD); tgt = pad_sequences(tgts, pad=PAD)\n",
    "    ko_lengths = torch.clamp(torch.tensor(ko_raws)+2, max=src.size(1))\n",
    "    en_lengths = torch.clamp(torch.tensor(en_raws)+2, max=tgt.size(1))\n",
    "    tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "    return src, ko_lengths, tgt_in, tgt_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Models + Attention\n",
    "# =====================\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(hid*2, hid)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "    def forward(self, x, lengths):\n",
    "        if not isinstance(lengths, torch.Tensor):\n",
    "            lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "        lengths = lengths.clamp(min=1, max=x.size(1)).cpu()\n",
    "        emb = self.drop(self.emb(x))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, h = self.gru(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=x.size(1))\n",
    "        h_cat = torch.cat([h[-2], h[-1]], dim=-1)\n",
    "        h0 = torch.tanh(self.proj(h_cat)).unsqueeze(0)\n",
    "        return out, h0\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, dec_hid, enc_dim, attn_dim=256):\n",
    "        super().__init__()\n",
    "        self.W_h = nn.Linear(dec_hid, attn_dim, bias=False)\n",
    "        self.W_e = nn.Linear(enc_dim, attn_dim, bias=False)\n",
    "        self.v   = nn.Linear(attn_dim, 1, bias=False)\n",
    "    def forward(self, dec_h, enc_out, src_mask):\n",
    "        q = self.W_h(dec_h).unsqueeze(1)\n",
    "        k = self.W_e(enc_out)\n",
    "        e = self.v(torch.tanh(q + k)).squeeze(-1)\n",
    "        e = e.masked_fill(~src_mask, float(\"-inf\"))\n",
    "        a = torch.softmax(e, dim=-1)\n",
    "        ctx = torch.bmm(a.unsqueeze(1), enc_out).squeeze(1)\n",
    "        return ctx, a\n",
    "\n",
    "class LuongGeneralAttention(nn.Module):\n",
    "    def __init__(self, dec_hid, enc_dim):\n",
    "        super().__init__()\n",
    "        self.key_proj = nn.Linear(enc_dim, dec_hid, bias=False)\n",
    "    def forward(self, dec_h, enc_out, src_mask):\n",
    "        key = self.key_proj(enc_out)\n",
    "        e = torch.bmm(key, dec_h.unsqueeze(-1)).squeeze(-1)\n",
    "        e = e.masked_fill(~src_mask, float(\"-inf\"))\n",
    "        a = torch.softmax(e, dim=-1)\n",
    "        ctx = torch.bmm(a.unsqueeze(1), enc_out).squeeze(1)\n",
    "        return ctx, a\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "    def forward(self, y_in, h0):\n",
    "        emb = self.drop(self.emb(y_in))\n",
    "        out, h = self.gru(emb, h0)\n",
    "        logits = self.out(out)\n",
    "        return logits, h\n",
    "    def step(self, y_t, h):\n",
    "        emb = self.drop(self.emb(y_t))\n",
    "        out, h = self.gru(emb, h)\n",
    "        logit = self.out(out)\n",
    "        return logit, h\n",
    "\n",
    "class AttnDecoderBahdanau(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid, enc_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb + enc_dim, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.attn = AdditiveAttention(hid, enc_dim)\n",
    "    def forward(self, y_in, h0, enc_out, src_mask):\n",
    "        B, T = y_in.size(); h = h0; logits=[]\n",
    "        for t in range(T):\n",
    "            emb_t = self.drop(self.emb(y_in[:, t:t+1]))\n",
    "            dec_h = h[-1]; ctx,_ = self.attn(dec_h, enc_out, src_mask)\n",
    "            rnn_in = torch.cat([emb_t.squeeze(1), ctx], dim=-1).unsqueeze(1)\n",
    "            out, h = self.gru(rnn_in, h); logits.append(self.out(out))\n",
    "        return torch.cat(logits, dim=1), h\n",
    "    def step(self, y_t, h, enc_out, src_mask):\n",
    "        emb_t = self.drop(self.emb(y_t))\n",
    "        dec_h = h[-1]; ctx,_ = self.attn(dec_h, enc_out, src_mask)\n",
    "        rnn_in = torch.cat([emb_t.squeeze(1), ctx], dim=-1).unsqueeze(1)\n",
    "        out, h = self.gru(rnn_in, h)\n",
    "        logit = self.out(out)\n",
    "        return logit, h\n",
    "\n",
    "class AttnDecoderLuong(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid, enc_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb + enc_dim, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.attn = LuongGeneralAttention(hid, enc_dim)\n",
    "    def forward(self, y_in, h0, enc_out, src_mask):\n",
    "        B, T = y_in.size(); h = h0; logits=[]\n",
    "        for t in range(T):\n",
    "            emb_t = self.drop(self.emb(y_in[:, t:t+1]))\n",
    "            dec_h = h[-1]; ctx,_ = self.attn(dec_h, enc_out, src_mask)\n",
    "            rnn_in = torch.cat([emb_t.squeeze(1), ctx], dim=-1).unsqueeze(1)\n",
    "            out, h = self.gru(rnn_in, h); logits.append(self.out(out))\n",
    "        return torch.cat(logits, dim=1), h\n",
    "    def step(self, y_t, h, enc_out, src_mask):\n",
    "        emb_t = self.drop(self.emb(y_t))\n",
    "        dec_h = h[-1]; ctx,_ = self.attn(dec_h, enc_out, src_mask)\n",
    "        rnn_in = torch.cat([emb_t.squeeze(1), ctx], dim=-1).unsqueeze(1)\n",
    "        out, h = self.gru(rnn_in, h)\n",
    "        logit = self.out(out)\n",
    "        return logit, h\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__(); self.enc = enc; self.dec = dec\n",
    "    def forward(self, src, src_len, tgt_in):\n",
    "        _, h0 = self.enc(src, src_len)\n",
    "        logits, _ = self.dec(tgt_in, h0)\n",
    "        return logits\n",
    "\n",
    "class Seq2SeqAttn(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__(); self.enc = enc; self.dec = dec\n",
    "    def forward(self, src, src_len, tgt_in):\n",
    "        enc_out, h0 = self.enc(src, src_len)\n",
    "        src_mask = (src != PAD)\n",
    "        logits, _ = self.dec(tgt_in, h0, enc_out, src_mask)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Train / Valid / Decode / Metrics\n",
    "# =====================\n",
    "def linear_tf_ratio(epoch, max_epoch, start=1.0, end=0.5):\n",
    "    if max_epoch <= 1: return end\n",
    "    t = epoch / (max_epoch - 1)\n",
    "    return float(start + (end - start)*t)\n",
    "\n",
    "def _is_attn_model(model): return isinstance(model, Seq2SeqAttn)\n",
    "\n",
    "def train_epoch_full_tf(model, dl, opt, criterion, device=\"cpu\"):\n",
    "    model.train(); total=0.0\n",
    "    for src, src_len, tgt_in, tgt_out in dl:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        logits = model(src, src_len, tgt_in)\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        opt.zero_grad(); loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 1.0); opt.step()\n",
    "        total += loss.item()\n",
    "    return total/len(dl)\n",
    "\n",
    "def train_epoch_scheduled_sampling(model, dl, opt, criterion, tf_ratio=0.9, device=\"cpu\"):\n",
    "    model.train(); total=0.0\n",
    "    for src, src_len, tgt_in, tgt_out in dl:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        if _is_attn_model(model):\n",
    "            enc_out, h = model.enc(src, src_len); src_mask = (src != PAD)\n",
    "            y = tgt_in[:, :1]; logits_steps=[]; T = tgt_out.size(1)\n",
    "            for t in range(T):\n",
    "                logit, h = model.dec.step(y[:, -1:], h, enc_out, src_mask)\n",
    "                logits_steps.append(logit)\n",
    "                use_tf = (torch.rand(1).item() < tf_ratio)\n",
    "                next_in = tgt_out[:, t:t+1] if use_tf else torch.argmax(logit[:, -1, :], dim=-1, keepdim=True)\n",
    "                y = torch.cat([y, next_in], dim=1)\n",
    "            logits = torch.cat(logits_steps, dim=1)\n",
    "        else:\n",
    "            _, h = model.enc(src, src_len); y = tgt_in[:, :1]; logits_steps=[]; T = tgt_out.size(1)\n",
    "            for t in range(T):\n",
    "                logit, h = model.dec.step(y[:, -1:], h)\n",
    "                logits_steps.append(logit)\n",
    "                use_tf = (torch.rand(1).item() < tf_ratio)\n",
    "                next_in = tgt_out[:, t:t+1] if use_tf else torch.argmax(logit[:, -1, :], dim=-1, keepdim=True)\n",
    "                y = torch.cat([y, next_in], dim=1)\n",
    "            logits = torch.cat(logits_steps, dim=1)\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        opt.zero_grad(); loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 1.0); opt.step()\n",
    "        total += loss.item()\n",
    "    return total/len(dl)\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_epoch(model, dl, criterion, device=\"cpu\"):\n",
    "    model.eval(); total=0.0\n",
    "    for src, src_len, tgt_in, tgt_out in dl:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
    "        logits = model(src, src_len, tgt_in)\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        total += loss.item()\n",
    "    ppl = float(np.exp(total/len(dl)))\n",
    "    return total/len(dl), ppl\n",
    "\n",
    "@torch.no_grad()\n",
    "def greedy_decode(model, src, tok_tgt, max_len=64, device=\"cpu\"):\n",
    "    model.eval(); src = src.to(device); src_len = torch.tensor([src.size(1)], dtype=torch.long)\n",
    "    if _is_attn_model(model):\n",
    "        enc_out, h0 = model.enc(src, src_len); src_mask = (src != PAD)\n",
    "        y = torch.tensor([[BOS]], device=device); outs=[]\n",
    "        for _ in range(max_len):\n",
    "            logit, h0 = model.dec.step(y[:, -1:], h0, enc_out, src_mask)\n",
    "            nxt = int(logit[:, -1, :].argmax(-1)); \n",
    "            if nxt == EOS: break\n",
    "            outs.append(nxt); y = torch.cat([y, torch.tensor([[nxt]], device=device)], dim=1)\n",
    "        return tok_tgt.decode(outs)\n",
    "    else:\n",
    "        _, h0 = model.enc(src, src_len); y = torch.tensor([[BOS]], device=device); outs=[]\n",
    "        for _ in range(max_len):\n",
    "            logit, h0 = model.dec.step(y[:, -1:], h0)\n",
    "            nxt = int(logit[:, -1, :].argmax(-1))\n",
    "            if nxt == EOS: break\n",
    "            outs.append(nxt); y = torch.cat([y, torch.tensor([[nxt]], device=device)], dim=1)\n",
    "        return tok_tgt.decode(outs)\n",
    "\n",
    "def simple_bleu(hyps, refs):\n",
    "    def prec(h, r):\n",
    "        ht, rt = h.split(), r.split()\n",
    "        if not ht: return 0.0\n",
    "        ch, cr = Counter(ht), Counter(rt)\n",
    "        overlap = sum(min(ch[w], cr[w]) for w in ch); return overlap/len(ht)\n",
    "    def bp(h, r):\n",
    "        len_h, len_r = len(h.split()), len(r.split())\n",
    "        if len_h == 0: return 0.0\n",
    "        return 1.0 if len_h > len_r else math.exp(1 - len_r/len_h)\n",
    "    scores = [100.0 * prec(h,r) * bp(h,r) for h,r in zip(hyps, refs)]\n",
    "    return sum(scores)/len(scores) if scores else 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_bleu(model, ds, tok_src, tok_tgt, device=\"cpu\", n_samples=None):\n",
    "    n = len(ds) if n_samples is None else min(n_samples, len(ds))\n",
    "    hyps, refs = [], []\n",
    "    for i in range(n):\n",
    "        src_ids, tgt_ids, *_ = ds[i]\n",
    "        hyp = greedy_decode(model, src_ids.unsqueeze(0), tok_tgt, max_len=CONFIG[\"tgt_max_len\"], device=device)\n",
    "        ref = tok_tgt.decode(tgt_ids.tolist())\n",
    "        hyps.append(hyp.strip()); refs.append(ref.strip())\n",
    "    if HAS_SACREBLEU: return sacrebleu.corpus_bleu(hyps, [refs]).score\n",
    "    return simple_bleu(hyps, refs)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_chrf(model, ds, tok_tgt, device=\"cpu\", n_samples=None):\n",
    "    if not HAS_SACREBLEU: return None\n",
    "    n = len(ds) if n_samples is None else min(n_samples, len(ds))\n",
    "    hyps, refs = [], []\n",
    "    for i in range(n):\n",
    "        src_ids, tgt_ids, *_ = ds[i]\n",
    "        hyps.append(greedy_decode(model, src_ids.unsqueeze(0), tok_tgt, max_len=CONFIG[\"tgt_max_len\"], device=device).strip())\n",
    "        refs.append(tok_tgt.decode(tgt_ids.tolist()).strip())\n",
    "    return sacrebleu.corpus_chrf(hyps, [refs]).score\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_random_samples(model, ds, tok_src, tok_tgt, k=10, device=\"cpu\"):\n",
    "    idxs = random.sample(range(len(ds)), min(k, len(ds)))\n",
    "    for i in idxs:\n",
    "        src_ids, tgt_ids, *_ = ds[i]\n",
    "        hyp = greedy_decode(model, src_ids.unsqueeze(0), tok_tgt, max_len=CONFIG[\"tgt_max_len\"], device=device)\n",
    "        print(f\"[{i}] KO:\", tok_src.decode(src_ids.tolist()))\n",
    "        print(\"REF:\", tok_tgt.decode(tgt_ids.tolist()))\n",
    "        print(\"HYP:\", hyp)\n",
    "        print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8542412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Runners\n",
    "# =====================\n",
    "def make_dataloaders(train_pairs, valid_pairs, tok_ko, tok_en, src_max, tgt_max, batch_size):\n",
    "    train_ds = NMTDataset(train_pairs, tok_ko, tok_en, src_max, tgt_max)\n",
    "    valid_ds = NMTDataset(valid_pairs, tok_ko, tok_en, src_max, tgt_max)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return train_ds, valid_ds, train_dl, valid_dl\n",
    "\n",
    "def build_model(attn, SRC_V, TGT_V):\n",
    "    enc = Encoder(SRC_V, CONFIG[\"emb\"], CONFIG[\"enc_hid\"])\n",
    "    if attn == \"none\":\n",
    "        dec = Decoder(TGT_V, CONFIG[\"emb\"], CONFIG[\"dec_hid\"]); model = Seq2Seq(enc, dec)\n",
    "    elif attn == \"bahdanau\":\n",
    "        dec = AttnDecoderBahdanau(TGT_V, CONFIG[\"emb\"], CONFIG[\"dec_hid\"], enc_dim=CONFIG[\"enc_hid\"]*2); model = Seq2SeqAttn(enc, dec)\n",
    "    elif attn == \"luong\":\n",
    "        dec = AttnDecoderLuong(TGT_V, CONFIG[\"emb\"], CONFIG[\"dec_hid\"], enc_dim=CONFIG[\"enc_hid\"]*2); model = Seq2SeqAttn(enc, dec)\n",
    "    else:\n",
    "        raise ValueError(\"attention must be one of: none|bahdanau|luong\")\n",
    "    return model.to(CONFIG[\"device\"])\n",
    "\n",
    "def run_once(attn=None, epochs=None):\n",
    "    attn = CONFIG[\"attention\"] if attn is None else attn\n",
    "    epochs = CONFIG[\"epochs\"] if epochs is None else epochs\n",
    "    train_ds, valid_ds, train_dl, valid_dl = make_dataloaders(\n",
    "        train_pairs_full, valid_pairs_full, tok_ko, tok_en, CONFIG[\"src_max_len\"], CONFIG[\"tgt_max_len\"], CONFIG[\"batch_size\"]\n",
    "    )\n",
    "    SRC_V, TGT_V = tok_ko.vocab_size(), tok_en.vocab_size()\n",
    "    model = build_model(attn, SRC_V, TGT_V)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "    crit = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "    hist_tr, hist_va = [], []\n",
    "    for e in range(epochs):\n",
    "        tf = linear_tf_ratio(e, epochs, CONFIG[\"tf_start\"], CONFIG[\"tf_end\"])\n",
    "        if CONFIG[\"tf_mode\"] == \"scheduled\":\n",
    "            tr = train_epoch_scheduled_sampling(model, train_dl, opt, crit, tf_ratio=tf, device=CONFIG[\"device\"])\n",
    "        else:\n",
    "            tr = train_epoch_full_tf(model, train_dl, opt, crit, device=CONFIG[\"device\"])\n",
    "        va, ppl = valid_epoch(model, valid_dl, crit, device=CONFIG[\"device\"])\n",
    "        hist_tr.append(tr); hist_va.append(va)\n",
    "        print(f\"[{attn}] ep{e+1}/{epochs} tf={tf:.2f} train={tr:.3f} valid={va:.3f} ppl={ppl:.2f}\")\n",
    "    bleu = eval_bleu(model, valid_ds, tok_ko, tok_en, device=CONFIG[\"device\"])\n",
    "    chrf = eval_chrf(model, valid_ds, tok_en, device=CONFIG[\"device\"])\n",
    "    print(f\"[{attn}] BLEU={bleu:.2f}\" + (f\" chrF={chrf:.2f}\" if chrf is not None else \"\"))\n",
    "    print(\"\\n=== Samples (k=5) ===\"); show_random_samples(model, valid_ds, tok_ko, tok_en, k=5, device=CONFIG[\"device\"])\n",
    "    return {\"attn\": attn, \"hist_tr\": hist_tr, \"hist_va\": hist_va, \"BLEU\": bleu, \"chrF\": chrf}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Sampling Experiments + Curves\n",
    "# =====================\n",
    "from caas_jupyter_tools import display_dataframe_to_user\n",
    "\n",
    "def subset_pairs(pairs, n, seed=42):\n",
    "    if n >= len(pairs): return pairs\n",
    "    rng = random.Random(seed); idx = list(range(len(pairs))); rng.shuffle(idx)\n",
    "    return [pairs[i] for i in idx[:n]]\n",
    "\n",
    "def plot_curve(y_tr, y_va, title, out_path):\n",
    "    plt.figure()\n",
    "    plt.plot(y_tr, label=\"train loss\"); plt.plot(y_va, label=\"valid loss\")\n",
    "    plt.title(title); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.savefig(out_path, dpi=150); plt.show()\n",
    "\n",
    "def run_experiment_for_size(N, attn):\n",
    "    train_pairs = subset_pairs(train_pairs_full, min(N, len(train_pairs_full)))\n",
    "    valid_pairs = subset_pairs(valid_pairs_full, min(N, len(valid_pairs_full)))\n",
    "    train_ds, valid_ds, train_dl, valid_dl = make_dataloaders(\n",
    "        train_pairs, valid_pairs, tok_ko, tok_en, CONFIG[\"src_max_len\"], CONFIG[\"tgt_max_len\"], CONFIG[\"batch_size\"]\n",
    "    )\n",
    "    SRC_V, TGT_V = tok_ko.vocab_size(), tok_en.vocab_size()\n",
    "    model = build_model(attn, SRC_V, TGT_V)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "    crit = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "    hist_tr, hist_va = [], []\n",
    "    for e in range(CONFIG[\"epochs\"]):\n",
    "        tf = linear_tf_ratio(e, CONFIG[\"epochs\"], CONFIG[\"tf_start\"], CONFIG[\"tf_end\"])\n",
    "        tr = train_epoch_scheduled_sampling(model, train_dl, opt, crit, tf_ratio=tf, device=CONFIG[\"device\"]) if CONFIG[\"tf_mode\"]==\"scheduled\" else              train_epoch_full_tf(model, train_dl, opt, crit, device=CONFIG[\"device\"])\n",
    "        va, ppl = valid_epoch(model, valid_dl, crit, device=CONFIG[\"device\"])\n",
    "        hist_tr.append(tr); hist_va.append(va)\n",
    "        print(f\"[N={N}][{attn}] ep{e+1}/{CONFIG['epochs']} tf={tf:.2f} train={tr:.3f} valid={va:.3f} ppl={ppl:.2f}\")\n",
    "    bleu = eval_bleu(model, valid_ds, tok_ko, tok_en, device=CONFIG[\"device\"])\n",
    "    chrf = eval_chrf(model, valid_ds, tok_en, device=CONFIG[\"device\"])\n",
    "    plot_curve(hist_tr, hist_va, f\"{attn.upper()} Loss (N={N})\", f\"curves/curve_{attn}_N{N}.png\")\n",
    "    return {\"N\": N, \"ATTN\": attn, \"BLEU\": bleu, \"chrF\": chrf, \"hist_tr\": hist_tr, \"hist_va\": hist_va}\n",
    "\n",
    "def run_sampling_experiments():\n",
    "    results = []\n",
    "    for N in CONFIG[\"sample_sizes\"]:\n",
    "        results.append(run_experiment_for_size(N, \"none\"))\n",
    "        if CONFIG[\"attention\"] in (\"bahdanau\", \"luong\"):\n",
    "            results.append(run_experiment_for_size(N, CONFIG[\"attention\"]))\n",
    "    df = pd.DataFrame(results)\n",
    "    display_dataframe_to_user(\"Sampling Experiment Summary (BLEU/chrF)\", df)\n",
    "    df.to_csv(\"sampling_results_all.csv\", index=False)\n",
    "    rows=[]\n",
    "    for r in results:\n",
    "        for i,v in enumerate(r[\"hist_tr\"]): rows.append({\"N\": r[\"N\"], \"ATTN\": r[\"ATTN\"], \"phase\":\"train\", \"epoch\":i+1, \"loss\":v})\n",
    "        for i,v in enumerate(r[\"hist_va\"]): rows.append({\"N\": r[\"N\"], \"ATTN\": r[\"ATTN\"], \"phase\":\"valid\", \"epoch\":i+1, \"loss\":v})\n",
    "    pd.DataFrame(rows).to_csv(\"sampling_curves_all.csv\", index=False)\n",
    "    print(\"[INFO] Saved sampling_results_all.csv & sampling_curves_all.csv and curve PNGs in ./curves/\")\n",
    "    return df\n",
    "\n",
    "print(\"Ready: run_once(attn='bahdanau'|'luong'|'none') or run_sampling_experiments()\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
