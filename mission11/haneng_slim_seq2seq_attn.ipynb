{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e52a21",
   "metadata": {},
   "source": [
    "\n",
    "# üá∞üá∑‚Üíüá∫üá∏ NMT Slim Version ‚Äî Seq2Seq (GRU) + (Optional) Bahdanau Attention\n",
    "\n",
    "**Î™©Ìëú(Goal)**  \n",
    "- ÏµúÏÜå Íµ¨ÏÑ±Ïùò **Seq2Seq(GRU)**ÏôÄ **Ïñ¥ÌÖêÏÖò(Bahdanau)** Î≤ÑÏ†ÑÏùÑ Îπ†Î•¥Í≤å ÌïôÏäµ/ÌèâÍ∞ÄÌï† Ïàò ÏûàÎäî **Ïä¨Î¶º ÎÖ∏Ìä∏Î∂Å**ÏûÖÎãàÎã§.  \n",
    "- **SentencePiece**Í∞Ä ÏóÜÏùÑ Í≤ΩÏö∞ ÏûêÎèôÏúºÎ°ú **Í≥µÎ∞± Í∏∞Î∞ò ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä**Î°ú Ìè¥Î∞±Ìï©ÎãàÎã§.  \n",
    "- ÌïôÏäµ ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ **ÌÜ†Ïù¥ Îç∞Ïù¥ÌÑ∞**Î•º ÏûêÎèô ÏÉùÏÑ±Ìï¥ end-to-end ÌÖåÏä§Ìä∏Í∞Ä Í∞ÄÎä•Ìï©ÎãàÎã§.\n",
    "\n",
    "**ÌïµÏã¨ Ìè¨Ïù∏Ìä∏**  \n",
    "- `collate_fn`ÏóêÏÑú **BOS/EOS Ìè¨Ìï® Í∏∏Ïù¥ clamp**  \n",
    "- `pack_padded_sequence(enforce_sorted=False)` + `pad_packed_sequence(total_length=...)`  \n",
    "- **Loss ÌÉÄÍπÉ ÏãúÌîÑÌä∏**(`logits[:, :-1]` vs `tgt[:, 1:]`)  \n",
    "- Í∞ÑÎã® **BLEU**(sacrebleu ÏûàÏúºÎ©¥ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ ÎÇ¥Î∂Ä Í∞ÑÏù¥ Íµ¨ÌòÑ)\n",
    "\n",
    "> Ïã§Ìñâ ÏàúÏÑú: ÏúÑÏóêÏÑú ÏïÑÎûòÎ°ú ÏàúÏÑúÎåÄÎ°ú Ïã§ÌñâÌïòÎ©¥ Îê©ÎãàÎã§.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0c8929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_json': 'ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_train_set.json',\n",
       " 'valid_json': 'ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_valid_set.json',\n",
       " 'use_sentencepiece': True,\n",
       " 'spm_vocab_ko': 8000,\n",
       " 'spm_vocab_en': 8000,\n",
       " 'src_max_len': 64,\n",
       " 'tgt_max_len': 64,\n",
       " 'batch_size': 128,\n",
       " 'emb': 256,\n",
       " 'enc_hid': 256,\n",
       " 'dec_hid': 256,\n",
       " 'epochs': 3,\n",
       " 'lr': 0.002,\n",
       " 'teacher_forcing_start': 1.0,\n",
       " 'teacher_forcing_end': 0.5,\n",
       " 'use_attention': True,\n",
       " 'use_scheduler': False,\n",
       " 'use_checkpoint': False,\n",
       " 'device': 'mps'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG = {\n",
    "    # Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú (Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏúºÎ©¥ ÌÜ†Ïù¥ Îç∞Ïù¥ÌÑ∞ ÏûêÎèô ÏÉùÏÑ±)\n",
    "    \"train_json\": \"ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_train_set.json\",\n",
    "    \"valid_json\": \"ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_valid_set.json\",\n",
    "\n",
    "    # ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä\n",
    "    \"use_sentencepiece\": True,      # sentencepiece ÎØ∏ÏÑ§Ïπò Ïãú ÏûêÎèô Ìè¥Î∞±\n",
    "    \"spm_vocab_ko\": 8000,\n",
    "    \"spm_vocab_en\": 8000,\n",
    "    \n",
    "    # Í∏∏Ïù¥/Î∞∞Ïπò\n",
    "    \"src_max_len\": 64,\n",
    "    \"tgt_max_len\": 64,\n",
    "    \"batch_size\": 128,\n",
    "    \n",
    "    # Î™®Îç∏ ÌÅ¨Í∏∞\n",
    "    \"emb\": 256,\n",
    "    \"enc_hid\": 256,\n",
    "    \"dec_hid\": 256,\n",
    "    \n",
    "    # ÌïôÏäµ\n",
    "    \"epochs\": 3,                # Îπ†Î•∏ ÌÖåÏä§Ìä∏Î•º ÏúÑÌï¥ ÏÜåÏàò ÏóêÌè≠\n",
    "    \"lr\": 2e-3,\n",
    "    \"teacher_forcing_start\": 1.0,\n",
    "    \"teacher_forcing_end\": 0.5,\n",
    "    \n",
    "    # ÏÑ†ÌÉù\n",
    "    \"use_attention\": True,      # Bahdanau Attention ÏÇ¨Ïö©\n",
    "    \"use_scheduler\": False,     # Ïä¨Î¶º Î≤ÑÏ†Ñ Í∏∞Î≥∏ OFF\n",
    "    \"use_checkpoint\": False,    # Ïä¨Î¶º Î≤ÑÏ†Ñ Í∏∞Î≥∏ OFF\n",
    "    \"device\": \"mps\",           # \"cuda\" ÎòêÎäî \"cpu\" (ÏûêÎèô Í∞êÏßÄ Î°úÏßÅÎèÑ ÏïÑÎûòÏóêÏÑú Ï≤òÎ¶¨)\n",
    "}\n",
    "\n",
    "CONFIG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eec0e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# Imports & Seed\n",
    "# =====================\n",
    "import os, json, math, random, re, sys, time\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Optional deps\n",
    "try:\n",
    "    import sentencepiece as spm\n",
    "    HAS_SPM = True\n",
    "except Exception:\n",
    "    HAS_SPM = False\n",
    "\n",
    "try:\n",
    "    import sacrebleu\n",
    "    HAS_SACREBLEU = True\n",
    "except Exception:\n",
    "    HAS_SACREBLEU = False\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # ÏóêÎü¨ ÏóÜÏù¥ ÏïàÏ†ÑÌïòÍ≤å Ï≤òÎ¶¨\n",
    "    try:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    except:\n",
    "        pass  # CUDAÍ∞Ä ÏóÜÏúºÎ©¥ Î¨¥Ïãú\n",
    "    \n",
    "    print(f\"Seed set to {seed}\")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# device\n",
    "CONFIG[\"device\"] = \"mps\" if (CONFIG[\"device\"]==\"mps\" and torch.backends.mps.is_available()) else \"cpu\"\n",
    "CONFIG[\"device\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49c5dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HAS_SPM, HAS_SACREBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ca949f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# Data Utils\n",
    "# =====================\n",
    "def basic_clean(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def ensure_data(train_path, valid_path):\n",
    "    \"\"\"Îç∞Ïù¥ÌÑ∞ ÌååÏùºÏù¥ ÏóÜÏúºÎ©¥ ÌÜ†Ïù¥ Îç∞Ïù¥ÌÑ∞(ÏûëÏùÄ Î≥ëÎ†¨ ÎßêÎ≠âÏπò)Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.\"\"\"\n",
    "    tp, vp = Path(train_path), Path(valid_path)\n",
    "    if tp.exists() and vp.exists():\n",
    "        train, valid = load_json(train_path), load_json(valid_path)\n",
    "        return train, valid\n",
    "    \n",
    "    print(\"[INFO] Îç∞Ïù¥ÌÑ∞ ÌååÏùºÏùÑ Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. ÌÜ†Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§.\")\n",
    "    toy_pairs = [\n",
    "        {\"ko\": \"ÏïàÎÖïÌïòÏÑ∏Ïöî\", \"mt\": \"Hello\"},\n",
    "        {\"ko\": \"Ïò§Îäò ÎÇ†Ïî® Ïñ¥ÎïåÏöî?\", \"mt\": \"How is the weather today?\"},\n",
    "        {\"ko\": \"Ïù¥Î¶ÑÏù¥ Î≠êÏòàÏöî?\", \"mt\": \"What is your name?\"},\n",
    "        {\"ko\": \"Í≥†ÎßàÏõåÏöî\", \"mt\": \"Thank you\"},\n",
    "        {\"ko\": \"ÏßÄÍ∏à Î™á ÏãúÏòàÏöî?\", \"mt\": \"What time is it now?\"},\n",
    "        {\"ko\": \"Ïª§Ìîº Ï¢ãÏïÑÌï¥Ïöî\", \"mt\": \"I like coffee\"},\n",
    "        {\"ko\": \"Ïñ¥Îîî Í∞ÄÏÑ∏Ïöî?\", \"mt\": \"Where are you going?\"},\n",
    "        {\"ko\": \"Î∞∞Í≥†ÌååÏöî\", \"mt\": \"I am hungry\"},\n",
    "        {\"ko\": \"ÎÇ¥Ïùº ÎßåÎÇòÏöî\", \"mt\": \"See you tomorrow\"},\n",
    "        {\"ko\": \"Ïûò ÏûêÏöî\", \"mt\": \"Good night\"},\n",
    "        {\"ko\": \"ÌïôÍµêÏóê Í∞ëÎãàÎã§\", \"mt\": \"I go to school\"},\n",
    "        {\"ko\": \"Ï±ÖÏùÑ ÏùΩÏäµÎãàÎã§\", \"mt\": \"I read a book\"},\n",
    "        {\"ko\": \"ÏùåÏïÖÏùÑ Îì£ÏäµÎãàÎã§\", \"mt\": \"I listen to music\"},\n",
    "        {\"ko\": \"ÏòÅÌôîÎ•º Î¥ÖÎãàÎã§\", \"mt\": \"I watch a movie\"},\n",
    "        {\"ko\": \"Ïö¥ÎèôÏùÑ Ìï©ÎãàÎã§\", \"mt\": \"I exercise\"},\n",
    "        {\"ko\": \"ÏöîÎ¶¨Î•º Ìï©ÎãàÎã§\", \"mt\": \"I cook\"},\n",
    "        {\"ko\": \"ÏπúÍµ¨Î•º ÎßåÎÇ©ÎãàÎã§\", \"mt\": \"I meet friends\"},\n",
    "        {\"ko\": \"ÏáºÌïëÏùÑ Ìï©ÎãàÎã§\", \"mt\": \"I go shopping\"},\n",
    "        {\"ko\": \"Ïó¨ÌñâÏùÑ Í∞ëÎãàÎã§\", \"mt\": \"I go traveling\"},\n",
    "        {\"ko\": \"Í≥µÎ∂ÄÎ•º Ìï©ÎãàÎã§\", \"mt\": \"I study\"}\n",
    "    ]\n",
    "    # 15 train, 5 valid\n",
    "    train = toy_pairs[:15]\n",
    "    valid = toy_pairs[15:]\n",
    "    Path(\"data\").mkdir(exist_ok=True)\n",
    "    with open(train_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train, f, ensure_ascii=False, indent=2)\n",
    "    with open(valid_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(valid, f, ensure_ascii=False, indent=2)\n",
    "    return train, valid\n",
    "\n",
    "train_pairs, valid_pairs = ensure_data(CONFIG[\"train_json\"], CONFIG[\"valid_json\"])\n",
    "len(train_pairs), len(valid_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec631ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA SIZE CHECK ===\n",
      "Train path: ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_train_set.json\n",
      "Valid path: ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_valid_set.json\n",
      "Train file size: 927.6 MB\n",
      "Valid file size: 115.9 MB\n",
      "Train samples: 1\n",
      "Error reading train data: 0\n",
      "Valid samples: 1\n",
      "Error reading valid data: 0\n"
     ]
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ ÌôïÏù∏\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# CONFIGÏóêÏÑú Í≤ΩÎ°ú Í∞ÄÏ†∏Ïò§Í∏∞ (fallback Ìè¨Ìï®)\n",
    "train_path = CONFIG.get(\"train_json\", \"ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_train_set.json\")\n",
    "valid_path = CONFIG.get(\"valid_json\", \"ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ/ÏùºÏÉÅÏÉùÌôúÎ∞èÍµ¨Ïñ¥Ï≤¥_ÌïúÏòÅ_valid_set.json\")\n",
    "\n",
    "print(\"=== DATA SIZE CHECK ===\")\n",
    "print(f\"Train path: {train_path}\")\n",
    "print(f\"Valid path: {valid_path}\")\n",
    "\n",
    "# ÌååÏùº Ï°¥Ïû¨ ÌôïÏù∏\n",
    "if Path(train_path).exists():\n",
    "    print(f\"Train file size: {Path(train_path).stat().st_size / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    print(\"Train file not found!\")\n",
    "\n",
    "if Path(valid_path).exists():\n",
    "    print(f\"Valid file size: {Path(valid_path).stat().st_size / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    print(\"Valid file not found!\")\n",
    "\n",
    "# ÏÉòÌîå Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
    "try:\n",
    "    with open(train_path, 'r', encoding='utf-8') as f:\n",
    "        train_data = json.load(f)\n",
    "        print(f\"Train samples: {len(train_data)}\")\n",
    "        if train_data and len(train_data) > 0:\n",
    "            print(f\"Sample data: {train_data[0]}\")\n",
    "        else:\n",
    "            print(\"Train data is empty\")\n",
    "except (FileNotFoundError, json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "    print(f\"Error reading train data: {e}\")\n",
    "\n",
    "try:\n",
    "    with open(valid_path, 'r', encoding='utf-8') as f:\n",
    "        valid_data = json.load(f)\n",
    "        print(f\"Valid samples: {len(valid_data)}\")\n",
    "        if valid_data and len(valid_data) > 0:\n",
    "            print(f\"Sample data: {valid_data[0]}\")\n",
    "        else:\n",
    "            print(\"Valid data is empty\")\n",
    "except (FileNotFoundError, json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "    print(f\"Error reading valid data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf42ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÏÉòÌîåÎßÅ Ìï®Ïàò\n",
    "def sample_data(data, sample_size=1000, random_seed=42):\n",
    "    \"\"\"Îç∞Ïù¥ÌÑ∞ÏóêÏÑú ÏßÄÏ†ïÎêú ÌÅ¨Í∏∞ÎßåÌÅº ÎûúÎç§ ÏÉòÌîåÎßÅ\"\"\"\n",
    "    import random\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    if len(data) <= sample_size:\n",
    "        return data\n",
    "    \n",
    "    sampled = random.sample(data, sample_size)\n",
    "    print(f\"Sampled {len(sampled)} from {len(data)} total samples\")\n",
    "    return sampled\n",
    "\n",
    "# Îã§ÏñëÌïú ÌÅ¨Í∏∞Î°ú ÏÉòÌîåÎßÅ\n",
    "SAMPLE_SIZES = [100, 500, 1000, 2000]  # ÌÖåÏä§Ìä∏Ïö© ÌÅ¨Í∏∞Îì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5f03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Tokenizer (SentencePiece or Whitespace)\n",
    "# =====================\n",
    "SPECIAL_TOKENS = {\"UNK\":0, \"BOS\":1, \"EOS\":2, \"PAD\":3}\n",
    "UNK, BOS, EOS, PAD = SPECIAL_TOKENS[\"UNK\"], SPECIAL_TOKENS[\"BOS\"], SPECIAL_TOKENS[\"EOS\"], SPECIAL_TOKENS[\"PAD\"]\n",
    "\n",
    "class WhitespaceTokenizer:\n",
    "    \"\"\"Í∞ÑÎã® Í≥µÎ∞± Í∏∞Î∞ò ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä + vocab ÎπåÎçî (SentencePiece Ìè¥Î∞±Ïö©)\"\"\"\n",
    "    def __init__(self, texts, vocab_size=8000):\n",
    "        print(f\"[INFO] Building WhitespaceTokenizer with {len(texts)} texts...\")\n",
    "        # Í≥µÎ∞± ÌÜ†ÌÅ∞ ÏàòÏßë\n",
    "        freq = Counter()\n",
    "        for t in texts:\n",
    "            tokens = basic_clean(t).split()\n",
    "            freq.update(tokens)\n",
    "        # ÎπàÎèÑ ÏÉÅÏúÑ vocab_size-4\n",
    "        most = [w for w,_ in freq.most_common(max(0, vocab_size-4))]\n",
    "        # ÏÇ¨Ï†Ñ\n",
    "        self.itos = [\"<unk>\", \"<bos>\", \"<eos>\", \"<pad>\"] + most\n",
    "        self.stoi = {w:i for i,w in enumerate(self.itos)}\n",
    "        print(f\"[INFO] WhitespaceTokenizer built: {len(self.itos)} tokens\")\n",
    "    \n",
    "    def encode(self, text):\n",
    "        toks = basic_clean(text).split()\n",
    "        return [self.stoi.get(t, UNK) for t in toks]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        # bos/eos/pad Ï†úÍ±∞\n",
    "        out = []\n",
    "        for i in ids:\n",
    "            if i in (BOS, EOS, PAD):\n",
    "                continue\n",
    "            out.append(self.itos[i] if 0 <= i < len(self.itos) else \"<unk>\")\n",
    "        return \" \".join(out)\n",
    "    \n",
    "    def vocab_size(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "class SentencePieceTokenizer:\n",
    "    def __init__(self, corpus_path, model_prefix, vocab_size=8000, coverage=0.9995):\n",
    "        print(f\"[INFO] Building SentencePieceTokenizer: {model_prefix}\")\n",
    "        # Î™®Îç∏Ïù¥ ÏóÜÏúºÎ©¥ ÌïôÏäµ\n",
    "        if not Path(model_prefix+\".model\").exists():\n",
    "            print(f\"[INFO] Training new SentencePiece model: {model_prefix}\")\n",
    "            spm.SentencePieceTrainer.train(\n",
    "                input=corpus_path, model_prefix=model_prefix, vocab_size=vocab_size,\n",
    "                model_type=\"unigram\", character_coverage=coverage,\n",
    "                unk_id=UNK, bos_id=BOS, eos_id=EOS, pad_id=PAD\n",
    "            )\n",
    "            print(f\"[INFO] SentencePiece model trained: {model_prefix}\")\n",
    "        else:\n",
    "            print(f\"[INFO] Loading existing SentencePiece model: {model_prefix}\")\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(model_prefix + \".model\")\n",
    "        print(f\"[INFO] SentencePieceTokenizer loaded: {model_prefix}\")\n",
    "        print(f\"[INFO] SentencePieceTokenizer ready: {self.sp.get_piece_size()} tokens\")\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return list(self.sp.encode(text, out_type=int))\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        # spmÏùÄ bos/eos/padÎ•º Î¨¥ÏãúÌïòÍ≥† decode\n",
    "        return self.sp.decode(ids)\n",
    "    \n",
    "    def vocab_size(self):\n",
    "        return self.sp.get_piece_size()\n",
    "\n",
    "def build_tokenizers(pairs_train, pairs_valid):\n",
    "    \"\"\"ko/en Í∞ÅÍ∞Å ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Íµ¨Ï∂ï. SentencePiece ÏûàÏúºÎ©¥ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ Í≥µÎ∞±Í∏∞Î∞ò.\"\"\"\n",
    "    print(\"[INFO] Building tokenizers...\")\n",
    "    # Check if pairs_train is a list of dictionaries or just strings\n",
    "    if isinstance(pairs_train, list) and pairs_train:\n",
    "        if isinstance(pairs_train[0], dict):\n",
    "            all_ko = [basic_clean(x[\"ko\"]) for x in pairs_train]\n",
    "            all_en = [basic_clean(x[\"mt\"]) for x in pairs_train]\n",
    "        else:\n",
    "            # If it's a list of strings, handle differently\n",
    "            print(f\"[DEBUG] pairs_train type: {type(pairs_train)}, first item: {pairs_train[0] if pairs_train else 'empty'}\")\n",
    "            raise ValueError(\"Expected pairs_train to be a list of dictionaries with 'ko' and 'mt' keys\")\n",
    "    else:\n",
    "        print(f\"[DEBUG] pairs_train type: {type(pairs_train)}, content: {pairs_train}\")\n",
    "        raise ValueError(\"Expected pairs_train to be a non-empty list\")\n",
    "    \n",
    "    print(f\"[INFO] Korean texts: {len(all_ko)}, English texts: {len(all_en)}\")\n",
    "\n",
    "    Path(\"spm\").mkdir(exist_ok=True)\n",
    "    \n",
    "    if CONFIG[\"use_sentencepiece\"] and HAS_SPM:\n",
    "        print(\"[INFO] Using SentencePiece tokenizers...\")\n",
    "        # ÌïôÏäµÏóê ÏÇ¨Ïö©Ìï† ÎßêÎ≠âÏπò Ï†ÄÏû•\n",
    "        ko_corpus, en_corpus = Path(\"spm/corpus.ko.txt\"), Path(\"spm/corpus.en.txt\")\n",
    "        print(f\"[INFO] Writing Korean corpus to {ko_corpus}\")\n",
    "        with open(ko_corpus, \"w\", encoding=\"utf-8\") as f:\n",
    "            for s in all_ko: f.write(s + \"\\n\")\n",
    "        print(f\"[INFO] Writing English corpus to {en_corpus}\")\n",
    "        with open(en_corpus, \"w\", encoding=\"utf-8\") as f:\n",
    "            for s in all_en: f.write(s + \"\\n\")\n",
    "        print(f\"[INFO] Building SentencePieceTokenizer for Korean: spm/ko\")\n",
    "        tok_ko = SentencePieceTokenizer(str(ko_corpus), \"spm/ko\", CONFIG[\"spm_vocab_ko\"], coverage=0.9995)\n",
    "        print(f\"[INFO] Building SentencePieceTokenizer for English: spm/en\")\n",
    "        tok_en = SentencePieceTokenizer(str(en_corpus), \"spm/en\", CONFIG[\"spm_vocab_en\"], coverage=1.0)\n",
    "        mode = \"SentencePiece\"\n",
    "    else:\n",
    "        print(\"[INFO] Using Whitespace tokenizers...\")\n",
    "        tok_ko = WhitespaceTokenizer(all_ko, vocab_size=CONFIG[\"spm_vocab_ko\"])\n",
    "        tok_en = WhitespaceTokenizer(all_en, vocab_size=CONFIG[\"spm_vocab_en\"])\n",
    "        mode = \"WhitespaceTokenizer\"\n",
    "    print(f\"[Tokenizer] mode={mode}, koV={tok_ko.vocab_size()}, enV={tok_en.vocab_size()}\")\n",
    "    return tok_ko, tok_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138569d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# CONFIG ÏàòÏ†ï\\nCONFIG[\"use_sentencepiece\"] = False\\nprint(\"Switched to WhitespaceTokenizer\")\\n\\n# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Ïû¨ÎπåÎìú\\ntok_ko, tok_en = build_tokenizers(train_pairs, valid_pairs)\\nprint(\"Tokenizers ready!\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# CONFIG ÏàòÏ†ï\n",
    "CONFIG[\"use_sentencepiece\"] = False\n",
    "print(\"Switched to WhitespaceTokenizer\")\n",
    "\n",
    "# ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Ïû¨ÎπåÎìú\n",
    "tok_ko, tok_en = build_tokenizers(train_pairs, valid_pairs)\n",
    "print(\"Tokenizers ready!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ad0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[INFO] Building tokenizers...\")\n",
    "tok_ko, tok_en = build_tokenizers(train_pairs, valid_pairs)\n",
    "print(\"[INFO] Tokenizers ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Dataset & Collate\n",
    "# =====================\n",
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, pairs, tok_ko, tok_en, src_max, tgt_max):\n",
    "        self.pairs = pairs\n",
    "        self.tok_ko = tok_ko\n",
    "        self.tok_en = tok_en\n",
    "        self.src_max = src_max\n",
    "        self.tgt_max = tgt_max\n",
    "    \n",
    "    def __len__(self): return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        ko = basic_clean(self.pairs[i][\"ko\"])\n",
    "        en = basic_clean(self.pairs[i][\"mt\"])\n",
    "        # encode\n",
    "        src_ids = [BOS] + self.tok_ko.encode(ko) + [EOS]\n",
    "        tgt_ids = [BOS] + self.tok_en.encode(en) + [EOS]\n",
    "        # truncate\n",
    "        src_ids = src_ids[:self.src_max]\n",
    "        tgt_ids = tgt_ids[:self.tgt_max]\n",
    "        # raw lengths (BOS/EOS Ï†úÏô∏Ìïú ÌÜ†ÌÅ∞ Í∏∏Ïù¥)\n",
    "        ko_raw = max(0, len(src_ids)-2)\n",
    "        en_raw = max(0, len(tgt_ids)-2)\n",
    "        return {\n",
    "            \"src\": torch.tensor(src_ids, dtype=torch.long),\n",
    "            \"tgt\": torch.tensor(tgt_ids, dtype=torch.long),\n",
    "            \"ko_raw\": ko_raw,\n",
    "            \"en_raw\": en_raw,\n",
    "        }\n",
    "\n",
    "def pad_sequences(seqs, pad=PAD):\n",
    "    maxlen = max(s.size(0) for s in seqs)\n",
    "    out = torch.full((len(seqs), maxlen), pad, dtype=torch.long)\n",
    "    lens = []\n",
    "    for i, s in enumerate(seqs):\n",
    "        out[i, :s.size(0)] = s\n",
    "        lens.append(int(s.size(0)))\n",
    "    return out, torch.tensor(lens, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs = [b[\"src\"] for b in batch]\n",
    "    tgts = [b[\"tgt\"] for b in batch]\n",
    "    src, _ = pad_sequences(srcs, PAD)\n",
    "    tgt, _ = pad_sequences(tgts, PAD)\n",
    "    # Ìö®Í≥ºÏ†Å Í∏∏Ïù¥: raw+2, Ìå®Îî© Í∏∏Ïù¥Î°ú clamp\n",
    "    ko_lengths = torch.clamp(torch.tensor([b[\"ko_raw\"] for b in batch]) + 2, max=src.size(1))\n",
    "    en_lengths = torch.clamp(torch.tensor([b[\"en_raw\"] for b in batch]) + 2, max=tgt.size(1))\n",
    "    # ÎîîÏΩîÎçîÏö© in/out Î∂ÑÎ¶¨\n",
    "    tgt_in  = tgt[:, :-1]\n",
    "    tgt_out = tgt[:, 1:]\n",
    "    return src, ko_lengths, tgt_in, tgt_out\n",
    "\n",
    "train_ds = NMTDataset(train_pairs, tok_ko, tok_en, CONFIG[\"src_max_len\"], CONFIG[\"tgt_max_len\"])\n",
    "valid_ds = NMTDataset(valid_pairs, tok_ko, tok_en, CONFIG[\"src_max_len\"], CONFIG[\"tgt_max_len\"])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "batch = next(iter(train_dl))\n",
    "print(\"sanity shapes:\", [x.shape if isinstance(x, torch.Tensor) else type(x) for x in batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Models: Encoder (BiGRU), Attention, Decoder\n",
    "# =====================\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb, hid, batch_first=True, bidirectional=True)\n",
    "        self.proj = nn.Linear(hid*2, hid)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        # lengths: clamp + cpu\n",
    "        if not isinstance(lengths, torch.Tensor):\n",
    "            lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "        lengths = lengths.clamp(min=1, max=x.size(1)).cpu()\n",
    "        emb = self.drop(self.emb(x))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out, h = self.gru(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=x.size(1))  # [B,S,2H]\n",
    "        h_cat = torch.cat([h[-2], h[-1]], dim=-1)  # [B,2H]\n",
    "        h0 = torch.tanh(self.proj(h_cat)).unsqueeze(0)  # [1,B,H]\n",
    "        return out, h0\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, dec_hid, enc_dim, attn_dim=256):\n",
    "        super().__init__()\n",
    "        self.W_h = nn.Linear(dec_hid, attn_dim, bias=False)\n",
    "        self.W_e = nn.Linear(enc_dim, attn_dim, bias=False)\n",
    "        self.v   = nn.Linear(attn_dim, 1, bias=False)\n",
    "    \n",
    "    def forward(self, dec_h, enc_out, src_mask):\n",
    "        # dec_h: [B,H], enc_out: [B,S,EncDim], src_mask: [B,S] (True for keep)\n",
    "        q = self.W_h(dec_h).unsqueeze(1)         # [B,1,A]\n",
    "        k = self.W_e(enc_out)                    # [B,S,A]\n",
    "        e = self.v(torch.tanh(q + k)).squeeze(-1)  # [B,S]\n",
    "        e = e.masked_fill(~src_mask, float(\"-inf\"))\n",
    "        a = torch.softmax(e, dim=-1)             # [B,S]\n",
    "        ctx = torch.bmm(a.unsqueeze(1), enc_out).squeeze(1)  # [B,EncDim]\n",
    "        return ctx, a\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, y_in, h0):\n",
    "        emb = self.drop(self.emb(y_in))       # [B,T,E]\n",
    "        out, h = self.gru(emb, h0)            # [B,T,H]\n",
    "        logits = self.out(out)                # [B,T,V]\n",
    "        return logits, h\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, vocab, emb, hid, enc_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab, emb, padding_idx=PAD)\n",
    "        self.gru = nn.GRU(emb + enc_dim, hid, batch_first=True)\n",
    "        self.out = nn.Linear(hid, vocab)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.attn = AdditiveAttention(hid, enc_dim)\n",
    "    \n",
    "    def forward(self, y_in, h0, enc_out, src_mask):\n",
    "        B, T = y_in.size()\n",
    "        h = h0\n",
    "        logits = []\n",
    "        for t in range(T):\n",
    "            emb_t = self.drop(self.emb(y_in[:, t:t+1]))  # [B,1,E]\n",
    "            dec_h = h[-1]                                 # [B,H]\n",
    "            ctx, _ = self.attn(dec_h, enc_out, src_mask)  # [B,EncDim]\n",
    "            rnn_in = torch.cat([emb_t.squeeze(1), ctx], dim=-1).unsqueeze(1)  # [B,1,E+EncDim]\n",
    "            out, h = self.gru(rnn_in, h)\n",
    "            logits.append(self.out(out))  # [B,1,V]\n",
    "        logits = torch.cat(logits, dim=1)  # [B,T,V]\n",
    "        return logits, h\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "    def forward(self, src, src_len, tgt_in):\n",
    "        enc_out, h0 = self.enc(src, src_len)\n",
    "        logits, _ = self.dec(tgt_in, h0)\n",
    "        return logits\n",
    "\n",
    "class Seq2SeqAttn(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "    def forward(self, src, src_len, tgt_in):\n",
    "        enc_out, h0 = self.enc(src, src_len)\n",
    "        src_mask = (src != PAD)\n",
    "        logits, _ = self.dec(tgt_in, h0, enc_out, src_mask)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Training / Validation / Decode / BLEU\n",
    "# =====================\n",
    "from math import exp\n",
    "\n",
    "def linear_tf_ratio(epoch, max_epoch, start=1.0, end=0.5):\n",
    "    if max_epoch <= 1: return end\n",
    "    t = epoch / (max_epoch - 1)\n",
    "    return float(start + (end - start)*t)\n",
    "\n",
    "def train_epoch(model, dl, opt, criterion, device=\"cpu\", teacher_forcing=1.0):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for src, src_len, tgt_in, tgt_out in dl:\n",
    "        src, src_len, tgt_in, tgt_out = src.to(device), src_len, tgt_in.to(device), tgt_out.to(device)\n",
    "        \n",
    "        # Teacher Forcing Ï†ÅÏö©\n",
    "        if random.random() < teacher_forcing:\n",
    "            # Teacher forcing: Ï†ïÎãµ ÏûÖÎ†• ÏÇ¨Ïö©\n",
    "            logits = model(src, src_len, tgt_in)\n",
    "        else:\n",
    "            # No teacher forcing: Î™®Îç∏ ÏòàÏ∏° ÏÇ¨Ïö©\n",
    "            # (Ïù¥ Î∂ÄÎ∂ÑÏùÄ Îçî Î≥µÏû°Ìïú Íµ¨ÌòÑ ÌïÑÏöî)\n",
    "            logits = model(src, src_len, tgt_in)\n",
    "        \n",
    "        # ÌÉÄÍπÉ ÏãúÌîÑÌä∏: collateÏóêÏÑú Ïù¥ÎØ∏ in/out Î∂ÑÎ¶¨ ÏôÑÎ£å\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    return total/len(dl)\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_epoch(model, dl, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total = 0.0\n",
    "    for src, src_len, tgt_in, tgt_out in dl:\n",
    "        src, src_len, tgt_in, tgt_out = src.to(device), src_len, tgt_in.to(device), tgt_out.to(device)\n",
    "        logits = model(src, src_len, tgt_in)\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        total += loss.item()\n",
    "    ppl = float(np.exp(total/len(dl)))\n",
    "    return total/len(dl), ppl\n",
    "\n",
    "@torch.no_grad()\n",
    "def greedy_decode(model, src, sp_tgt, max_len=64, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    src = src.to(device)\n",
    "    src_len = torch.tensor([src.size(1)], dtype=torch.long)\n",
    "    # Ïù∏ÏΩîÎìú\n",
    "    if isinstance(model, Seq2Seq):\n",
    "        enc_out, h0 = model.enc(src, src_len)\n",
    "        y = torch.tensor([[BOS]], device=device)\n",
    "        h = h0\n",
    "        out_ids = []\n",
    "        for _ in range(max_len):\n",
    "            logits, h = model.dec(y, h)  # [1,T,V]\n",
    "            next_id = int(logits[:, -1, :].argmax(-1))\n",
    "            if next_id == EOS: break\n",
    "            out_ids.append(next_id)\n",
    "            y = torch.cat([y, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "        return sp_tgt.decode(out_ids)\n",
    "    else:\n",
    "        enc_out, h0 = model.enc(src, src_len)\n",
    "        src_mask = (src != PAD)\n",
    "        y = torch.tensor([[BOS]], device=device)\n",
    "        h = h0\n",
    "        out_ids = []\n",
    "        for _ in range(max_len):\n",
    "            # Ìïú Ïä§ÌÖù\n",
    "            emb = model.dec.emb(y[:, -1:])   # [1,1,E]\n",
    "            dec_h = h[-1]                    # [1,H]\n",
    "            ctx, _ = model.dec.attn(dec_h, enc_out, src_mask)\n",
    "            rnn_in = torch.cat([emb.squeeze(1), ctx], dim=-1).unsqueeze(1)\n",
    "            o, h = model.dec.gru(rnn_in, h)\n",
    "            logit = model.dec.out(o)         # [1,1,V]\n",
    "            nxt = int(logit[:, -1, :].argmax(-1))\n",
    "            if nxt == EOS: break\n",
    "            out_ids.append(nxt)\n",
    "            y = torch.cat([y, torch.tensor([[nxt]], device=device)], dim=1)\n",
    "        return sp_tgt.decode(out_ids)\n",
    "\n",
    "# BLEU: sacrebleu ÏûàÏúºÎ©¥ ÏÇ¨Ïö©, ÏóÜÏúºÎ©¥ Îß§Ïö∞ Í∞ÑÎã®Ìïú ÎåÄÏ≤¥(Ïú†ÎãàÍ∑∏Îû® BLEU ÎπÑÏä∑)\n",
    "def simple_bleu(hyps, refs):\n",
    "    # ÏïÑÏ£º Í∞ÑÎã®: Ïú†ÎãàÍ∑∏Îû® precision * brevity penalty\n",
    "    def prec(h, r):\n",
    "        ht = h.split()\n",
    "        rt = r.split()\n",
    "        if not ht: return 0.0\n",
    "        count_h = Counter(ht)\n",
    "        count_r = Counter(rt)\n",
    "        overlap = sum(min(count_h[w], count_r[w]) for w in count_h)\n",
    "        return overlap / len(ht)\n",
    "    def bp(h, r):\n",
    "        len_h = len(h.split())\n",
    "        len_r = len(r.split())\n",
    "        if len_h==0: return 0.0\n",
    "        return 1.0 if len_h>len_r else math.exp(1 - len_r/len_h) if len_h>0 else 0.0\n",
    "    \n",
    "    scores = []\n",
    "    for h, r in zip(hyps, refs):\n",
    "        scores.append(100.0 * prec(h, r) * bp(h, r))\n",
    "    return sum(scores)/len(scores) if scores else 0.0\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_bleu(model, ds, tok_src, tok_tgt, n_samples=200, device=\"cpu\"):\n",
    "    n = min(n_samples, len(ds))\n",
    "    hyps, refs = [], []\n",
    "    for i in range(n):\n",
    "        item = ds[i]\n",
    "        src = item[\"src\"].unsqueeze(0)  # [1,S]\n",
    "        hyp = greedy_decode(model, src, tok_tgt, max_len=CONFIG[\"tgt_max_len\"], device=device)\n",
    "        ref = tok_tgt.decode(item[\"tgt\"].tolist())\n",
    "        hyps.append(hyp.strip())\n",
    "        refs.append(ref.strip())\n",
    "    if HAS_SACREBLEU:\n",
    "        return sacrebleu.corpus_bleu(hyps, [refs]).score\n",
    "    else:\n",
    "        return simple_bleu(hyps, refs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Train & Evaluate\n",
    "# =====================\n",
    "device = CONFIG[\"device\"]\n",
    "\n",
    "SRC_V = tok_ko.vocab_size()\n",
    "TGT_V = tok_en.vocab_size()\n",
    "\n",
    "enc = Encoder(SRC_V, CONFIG[\"emb\"], CONFIG[\"enc_hid\"])\n",
    "dec_base = Decoder(TGT_V, CONFIG[\"emb\"], CONFIG[\"dec_hid\"])\n",
    "model_base = Seq2Seq(enc, dec_base).to(device)\n",
    "\n",
    "encA = Encoder(SRC_V, CONFIG[\"emb\"], CONFIG[\"enc_hid\"])\n",
    "dec_attn = AttnDecoder(TGT_V, CONFIG[\"emb\"], CONFIG[\"dec_hid\"], enc_dim=CONFIG[\"enc_hid\"]*2)\n",
    "model_attn = Seq2SeqAttn(encA, dec_attn).to(device) if CONFIG[\"use_attention\"] else None\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "opt_base = torch.optim.Adam(model_base.parameters(), lr=CONFIG[\"lr\"])\n",
    "opt_attn = torch.optim.Adam(model_attn.parameters(), lr=CONFIG[\"lr\"]) if model_attn else None\n",
    "\n",
    "# Train baseline\n",
    "print(\"== Train: Seq2Seq (baseline) ==\")\n",
    "for e in range(CONFIG[\"epochs\"]):\n",
    "    tf = linear_tf_ratio(e, CONFIG[\"epochs\"], CONFIG[\"teacher_forcing_start\"], CONFIG[\"teacher_forcing_end\"])\n",
    "    tr = train_epoch(model_base, train_dl, opt_base, criterion, device=device, teacher_forcing=tf)\n",
    "    va, ppl = valid_epoch(model_base, valid_dl, criterion, device=device)\n",
    "    print(f\"[BASE] ep{e+1}/{CONFIG['epochs']}  train {tr:.3f}  valid {va:.3f}  ppl {ppl:.2f}\")\n",
    "\n",
    "bleu_b = eval_bleu(model_base, valid_ds, tok_ko, tok_en, n_samples=min(200, len(valid_ds)), device=device)\n",
    "print(f\"[BASE] BLEU(valid): {bleu_b:.2f}\")\n",
    "\n",
    "# Train attention (optional)\n",
    "if model_attn:\n",
    "    print(\"\\n== Train: Seq2Seq + Bahdanau Attention ==\")\n",
    "    for e in range(CONFIG[\"epochs\"]):\n",
    "        tf = linear_tf_ratio(e, CONFIG[\"epochs\"], CONFIG[\"teacher_forcing_start\"], CONFIG[\"teacher_forcing_end\"])\n",
    "        tr = train_epoch(model_attn, train_dl, opt_attn, criterion, device=device, teacher_forcing=tf)\n",
    "        va, ppl = valid_epoch(model_attn, valid_dl, criterion, device=device)\n",
    "        print(f\"[ATTN] ep{e+1}/{CONFIG['epochs']}  train {tr:.3f}  valid {va:.3f}  ppl {ppl:.2f}\")\n",
    "    bleu_a = eval_bleu(model_attn, valid_ds, tok_ko, tok_en, n_samples=min(200, len(valid_ds)), device=device)\n",
    "    print(f\"[ATTN] BLEU(valid): {bleu_a:.2f}\")\n",
    "else:\n",
    "    print(\"[INFO] Attention Î™®Îç∏ÏùÄ ÎπÑÌôúÏÑ±ÌôîÎê® (CONFIG['use_attention']=False).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================\n",
    "# Sample Translations\n",
    "# =====================\n",
    "@torch.no_grad()\n",
    "def show_samples(model, ds, tok_src, tok_tgt, k=5, device=\"cpu\"):\n",
    "    print(\"----- Sample translations -----\")\n",
    "    for i in range(min(k, len(ds))):\n",
    "        item = ds[i]\n",
    "        src_text = basic_clean(train_pairs[i][\"ko\"]) if i < len(train_pairs) else \"<src>\"\n",
    "        ref_text = basic_clean(train_pairs[i][\"mt\"]) if i < len(train_pairs) else \"<ref>\"\n",
    "        hyp = greedy_decode(model, item[\"src\"].unsqueeze(0), tok_tgt, max_len=CONFIG[\"tgt_max_len\"], device=device)\n",
    "        print(f\"KO: {src_text}\")\n",
    "        print(f\"REF: {ref_text}\")\n",
    "        print(f\"HYP: {hyp}\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "print(\"\\n[Samples: baseline]\")\n",
    "show_samples(model_base, valid_ds, tok_ko, tok_en, k=min(5, len(valid_ds)), device=device)\n",
    "\n",
    "if model_attn:\n",
    "    print(\"\\n[Samples: attention]\")\n",
    "    show_samples(model_attn, valid_ds, tok_ko, tok_en, k=min(5, len(valid_ds)), device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5027a7d",
   "metadata": {},
   "source": [
    "\n",
    "### Ï†ÄÏû•/Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏(ÏòµÏÖò)\n",
    "- Ïä¨Î¶º Î≤ÑÏ†ÑÏóêÏÑúÎäî Í∏∞Î≥∏ **OFF**ÏûÖÎãàÎã§. ÌïÑÏöî Ïãú Îã§ÏùåÏùÑ Ï∞∏Í≥†:\n",
    "```python\n",
    "if CONFIG[\"use_checkpoint\"]:\n",
    "    torch.save(model_base.state_dict(), \"model_base.pt\")\n",
    "    if CONFIG[\"use_attention\"]:\n",
    "        torch.save(model_attn.state_dict(), \"model_attn.pt\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_3 (conda)",
   "language": "python",
   "name": "ai_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
