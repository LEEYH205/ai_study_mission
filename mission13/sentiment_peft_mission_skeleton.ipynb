{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 쇼핑몰 리뷰 감성 분석 — **Full Fine-Tuning vs PEFT (LoRA)** 스켈레톤\n\n> 버전: 2025-09-03 · 작성자: *스켈레톤 자동 생성*  \n본 노트북은 **쇼핑몰 리뷰 데이터(JSON)**를 이용해 감성 분석을 수행하는 **스켈레톤**입니다.  \n두 가지 학습 방식(**Full Fine-Tuning**, **PEFT/LoRA**)을 동일 파이프라인에서 비교할 수 있도록 구성되어 있습니다.\n\n## 미션 개요\n- **데이터 전처리** → **학습/검증 분할** → **토크나이징/데이터세트 구성**\n- **Full FT** 학습/평가/저장\n- **PEFT(LoRA)** 학습/평가/저장\n- **학습 시간/정확도/저장 용량 비교** 및 간단 시각화\n- 각 셀의 의도/설명을 **마크다운**으로 정리하여 리포트처럼 읽히도록 구성\n\n> 💡 본 문서는 **스켈레톤**이므로, 필요에 맞게 **하이퍼파라미터·모델·전처리**를 조정하세요.  \n> 💡 한국어 데이터에 적합한 베이스 모델(예: `klue/bert-base`)을 기본값으로 제공합니다."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🧭 Runbook (실행 가이드)\n\n1. **환경 준비**\n   - (로컬/Colab) 필요한 라이브러리 설치:\n     ```bash\n     pip install -q \"transformers>=4.41.0\" \"datasets>=2.19.0\" \"peft>=0.11.0\" \"accelerate>=0.32.0\" evaluate scikit-learn matplotlib pandas\n     ```\n   - GPU 사용 가능 시 `accelerate`가 알아서 최적 기기를 선택합니다.\n\n2. **데이터 위치 지정**\n   - 데이터는 **JSON 파일**이며, 필드:\n     - `RawText`: 리뷰 텍스트\n     - `GeneralPolarity`: 감성 레이블 (`-1`=부정, `0`=중립, `1`=긍정)\n   - zip 압축이라면 노트북과 같은 폴더에 두고, 아래 **데이터 로드** 셀에서 경로(`DATA_ZIP_PATH`/`DATA_DIR`)를 설정하세요.\n\n3. **전처리 & 분할**\n   - 불용어 처리/이모지 제거 등은 **선택**입니다. 우선은 최소 전처리로 시작하세요.\n   - 기본은 **3-클래스(부정/중립/긍정)** 분류. 원하면 중립을 제외해 **2-클래스**로 바꿀 수 있습니다.\n\n4. **학습**\n   - **Full FT** → **PEFT(LoRA)** 순으로 실행.\n   - 각 학습 블록은 **시간 측정** 및 **메트릭**을 자동 로깅합니다.\n\n5. **비교 & 리포트**\n   - 학습 시간, 정확도/F1, 저장 용량(MB)을 표/차트로 비교.\n   - 필요한 경우 WandB/MLflow 연동 섹션을 추가하세요."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 📦 의존성 설치 (필요 시 실행)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Colab/로컬에서 필요 시 주석 해제하여 실행\n# %pip install -q \"transformers>=4.41.0\" \"datasets>=2.19.0\" \"peft>=0.11.0\" \"accelerate>=0.32.0\" evaluate scikit-learn matplotlib pandas\n\nimport os, sys, math, time, json, random, shutil, pathlib, zipfile\nfrom typing import List, Dict, Any, Optional\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nprint(f\"PyTorch: {torch.__version__}, CUDA available: {torch.cuda.is_available()}\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\n\nimport evaluate\nfrom datasets import Dataset, DatasetDict\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer,\n    set_seed\n)\n\nfrom peft import LoraConfig, get_peft_model, TaskType"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ⚙️ 설정 (경로/모델/하이퍼파라미터)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# === 데이터 경로 ===\nDATA_ZIP_PATH = \"review-sentiment-analysis.zip\"   # 예: 노트북과 같은 폴더에 위치\nDATA_DIR = \"data\"                                  # 압축 해제될 폴더\n\n# 직접 JSON 폴더를 지정할 수도 있습니다 (zip 미사용 시)\n# DATA_DIR = \"/path/to/json_dir\"\n\n# JSON 파일을 찾을 글롭 패턴 (하위 폴더 포함)\nGLOB_PATTERN = \"**/*.json\"\n\n# 필드명 (데이터셋 스키마에 맞게 변경 가능)\nTEXT_FIELD = \"RawText\"\nLABEL_FIELD = \"GeneralPolarity\"\n\n# 라벨 매핑 (3-클래스)\nLABEL_MAP = {-1: 0, 0: 1, 1: 2}\nID2LABEL = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\nLABEL2ID = {v: k for k, v in ID2LABEL.items()}\n\n# 중립 제외하고 2-클래스(Binary)로 바꾸려면 아래 플래그 사용\nBINARY_CLASS = False  # True로 두면 neutral 제외 (부정/긍정만)\n\n# 선택적 도메인 필터 (예: [\"패션\", \"화장품\"] 등). 메타에 domain 키가 있을 때만 사용\nDOMAIN_FILTER: Optional[list] = None  # 또는 [\"패션\", \"화장품\"]\n\n# === 모델 & 토크나이저 ===\nBASE_MODEL_NAME = \"klue/bert-base\"\nMAX_LENGTH = 256\n\n# === 학습 하이퍼파라미터 ===\nSEED = 42\nEPOCHS = 2\nBATCH_SIZE = 16\nLR_FT = 5e-5\nLR_PEFT = 5e-5\n\n# 출력/저장 경로\nOUT_DIR = \"outputs\"\nFT_DIR = os.path.join(OUT_DIR, \"full_ft_model\")\nPEFT_DIR = os.path.join(OUT_DIR, \"peft_lora_adapter\")\n\nos.makedirs(OUT_DIR, exist_ok=True)\n\nset_seed(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\ndef human_mb(bytes_size: int) -> float:\n    return round(bytes_size / (1024 * 1024), 2)\n\ndef dir_size_mb(path: str) -> float:\n    total = 0\n    for root, _, files in os.walk(path):\n        for f in files:\n            fp = os.path.join(root, f)\n            if os.path.isfile(fp):\n                total += os.path.getsize(fp)\n    return human_mb(total)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 📥 데이터 로드 & 전처리"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ndef _extract_records_from_json(obj):\n    r\"\"\"\n    다양한 JSON 스키마를 최대한 견고하게 파싱하여\n    [{TEXT_FIELD: str, LABEL_FIELD: int, ...(optional: domain)}] 리스트로 반환.\n    \"\"\"\n    records = []\n    if isinstance(obj, list):\n        for item in obj:\n            if isinstance(item, dict):\n                records.append(item)\n    elif isinstance(obj, dict):\n        if \"reviews\" in obj and isinstance(obj[\"reviews\"], list):\n            for item in obj[\"reviews\"]:\n                if isinstance(item, dict):\n                    records.append(item)\n        else:\n            records.append(obj)\n    return records\n\ndef load_json_files(data_dir: str, glob_pattern: str = \"**/*.json\") -> pd.DataFrame:\n    import glob\n    paths = glob.glob(os.path.join(data_dir, glob_pattern), recursive=True)\n    rows = []\n    for p in paths:\n        try:\n            with open(p, \"r\", encoding=\"utf-8\") as f:\n                obj = json.load(f)\n            recs = _extract_records_from_json(obj)\n            for r in recs:\n                if TEXT_FIELD in r and LABEL_FIELD in r:\n                    rows.append({\n                        \"text\": str(r[TEXT_FIELD]),\n                        \"label_raw\": r[LABEL_FIELD],\n                        \"domain\": r.get(\"domain\") or r.get(\"category\") or None,\n                        \"__src__\": p\n                    })\n        except Exception as e:\n            print(f\"[WARN] JSON parse failed: {p} -> {e}\")\n    df = pd.DataFrame(rows)\n    return df\n\ndef basic_clean(text: str) -> str:\n    text = text.replace(\"\\n\", \" \").strip()\n    return text\n\n# Zip 해제 (존재할 경우)\nif os.path.exists(DATA_ZIP_PATH):\n    print(f\"Unzipping: {DATA_ZIP_PATH} -> {DATA_DIR}\")\n    os.makedirs(DATA_DIR, exist_ok=True)\n    with zipfile.ZipFile(DATA_ZIP_PATH, 'r') as zf:\n        zf.extractall(DATA_DIR)\n\ndf = load_json_files(DATA_DIR, GLOB_PATTERN)\nif len(df) == 0:\n    raise RuntimeError(\"데이터가 비어있습니다. DATA_ZIP_PATH/DATA_DIR 경로와 JSON 스키마를 확인하세요.\")\n\nif DOMAIN_FILTER:\n    df = df[df[\"domain\"].isin(DOMAIN_FILTER)]\n\nif BINARY_CLASS:\n    df = df[df[\"label_raw\"].isin([-1, 1])].copy()\n    df[\"label\"] = (df[\"label_raw\"] == 1).astype(int)\n    ID2LABEL = {0: \"negative\", 1: \"positive\"}\n    LABEL2ID = {v: k for k, v in ID2LABEL.items()}\n    NUM_LABELS = 2\nelse:\n    df[\"label\"] = df[\"label_raw\"].map(LABEL_MAP)\n    NUM_LABELS = 3\n\ndf[\"text\"] = df[\"text\"].astype(str).map(basic_clean)\ndf = df.dropna(subset=[\"text\", \"label\"]).reset_index(drop=True)\n\nprint(\"샘플:\")\ndisplay(df.head(3))\nprint(\"라벨 분포:\")\ndisplay(df[\"label\"].value_counts(normalize=False).rename_axis(\"label\").to_frame(\"count\"))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🔀 학습/검증 분할"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ntrain_df, test_df = train_test_split(\n    df, \n    test_size=0.2, \n    random_state=SEED, \n    stratify=df[\"label\"]\n)\nprint(f\"train={len(train_df)}, test={len(test_df)}\")\n\ntrain_ds = Dataset.from_pandas(train_df[[\"text\",\"label\"]], preserve_index=False)\ntest_ds  = Dataset.from_pandas(test_df[[\"text\",\"label\"]], preserve_index=False)\nraw_datasets = DatasetDict({\"train\": train_ds, \"test\": test_ds})\nraw_datasets"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🔡 토크나이저 & 데이터셋 구성"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, use_fast=True)\n\ndef tokenize_fn(batch):\n    return tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        max_length=MAX_LENGTH\n    )\n\ntok_datasets = raw_datasets.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntok_datasets"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🧠 Baseline: Full Fine-Tuning"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nft_model = AutoModelForSequenceClassification.from_pretrained(\n    BASE_MODEL_NAME, \n    num_labels=NUM_LABELS, \n    id2label=ID2LABEL, \n    label2id=LABEL2ID\n)\n\nmetric_accuracy = evaluate.load(\"accuracy\")\nmetric_f1 = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    acc = metric_accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n    f1_macro = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n    return {\"accuracy\": acc, \"f1_macro\": f1_macro}\n\nft_args = TrainingArguments(\n    output_dir=os.path.join(OUT_DIR, \"ft_tmp\"),\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    learning_rate=LR_FT,\n    num_train_epochs=EPOCHS,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    greater_is_better=True,\n    report_to=[],\n    seed=SEED\n)\n\nft_trainer = Trainer(\n    model=ft_model,\n    args=ft_args,\n    train_dataset=tok_datasets[\"train\"],\n    eval_dataset=tok_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nt0 = time.perf_counter()\nft_train_out = ft_trainer.train()\nft_train_sec = time.perf_counter() - t0\n\nft_eval = ft_trainer.evaluate()\nprint(\"Full FT eval:\", ft_eval)\n\n# 저장\nif os.path.exists(OUT_DIR):\n    os.makedirs(OUT_DIR, exist_ok=True)\nif os.path.exists(\"ft_tmp\"):\n    pass\n\nif os.path.exists(FT_DIR):\n    import shutil as _shutil\n    _shutil.rmtree(FT_DIR)\nft_trainer.save_model(FT_DIR)\ntokenizer.save_pretrained(FT_DIR)\n\nft_size_mb = dir_size_mb(FT_DIR)\nprint(f\"[Full FT] 저장 용량: {ft_size_mb} MB\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 🔧 PEFT (LoRA) 학습"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\npeft_base = AutoModelForSequenceClassification.from_pretrained(\n    BASE_MODEL_NAME, \n    num_labels=NUM_LABELS, \n    id2label=ID2LABEL, \n    label2id=LABEL2ID\n)\n\ntarget_modules = [\"query\", \"key\", \"value\", \"dense\"]\n\nlora_cfg = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    inference_mode=False,\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    target_modules=target_modules\n)\n\npeft_model = get_peft_model(peft_base, lora_cfg)\npeft_model.print_trainable_parameters()\n\npeft_args = TrainingArguments(\n    output_dir=os.path.join(OUT_DIR, \"peft_tmp\"),\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    learning_rate=LR_PEFT,\n    num_train_epochs=EPOCHS,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    greater_is_better=True,\n    report_to=[],\n    seed=SEED\n)\n\npeft_trainer = Trainer(\n    model=peft_model,\n    args=peft_args,\n    train_dataset=tok_datasets[\"train\"],\n    eval_dataset=tok_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nt0 = time.perf_counter()\npeft_train_out = peft_trainer.train()\npeft_train_sec = time.perf_counter() - t0\n\npeft_eval = peft_trainer.evaluate()\nprint(\"PEFT eval:\", peft_eval)\n\n# 어댑터만 저장\nimport shutil as _shutil\nif os.path.exists(PEFT_DIR):\n    _shutil.rmtree(PEFT_DIR)\npeft_trainer.model.save_pretrained(PEFT_DIR)\ntokenizer.save_pretrained(PEFT_DIR)\n\npeft_size_mb = dir_size_mb(PEFT_DIR)\nprint(f\"[PEFT] 저장 용량(어댑터): {peft_size_mb} MB\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 📊 두 방식 비교 (시간 · 정확도 · 용량)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport pandas as _pd\nsummary = _pd.DataFrame([\n    {\n        \"approach\": \"Full FT\",\n        \"train_sec\": round(ft_train_sec, 2),\n        \"accuracy\": round(float(ft_eval.get(\"eval_accuracy\", float(\"nan\"))), 4),\n        \"f1_macro\": round(float(ft_eval.get(\"eval_f1_macro\", float(\"nan\"))), 4),\n        \"saved_size_mb\": ft_size_mb\n    },\n    {\n        \"approach\": \"PEFT (LoRA)\",\n        \"train_sec\": round(peft_train_sec, 2),\n        \"accuracy\": round(float(peft_eval.get(\"eval_accuracy\", float(\"nan\"))), 4),\n        \"f1_macro\": round(float(peft_eval.get(\"eval_f1_macro\", float(\"nan\"))), 4),\n        \"saved_size_mb\": peft_size_mb\n    }\n])\n\ndisplay(summary)\n\nimport matplotlib.pyplot as _plt\n\n_plt.figure()\n_plt.bar(summary[\"approach\"], summary[\"saved_size_mb\"])\n_plt.title(\"저장 용량 비교 (MB)\")\n_plt.ylabel(\"MB\")\n_plt.show()\n\n_plt.figure()\n_plt.bar(summary[\"approach\"], summary[\"accuracy\"])\n_plt.title(\"정확도(Accuracy) 비교\")\n_plt.ylabel(\"accuracy\")\n_plt.ylim(0, 1)\n_plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 📝 참고 & 트러블슈팅"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "- **JSON 스키마가 다른 경우**: `TEXT_FIELD`, `LABEL_FIELD`, `_extract_records_from_json()` 수정\n- **2-클래스(부정/긍정)만 사용**: `BINARY_CLASS=True` 설정\n- **PEFT 타깃 모듈 에러**: 모델 구조에 맞게 `target_modules` 수정 (예: `query_proj`, `value_proj` 등)\n- **속도 개선**: `fp16=True`(AMP), `gradient_accumulation_steps`, 짧은 `MAX_LENGTH` 등\n- **추가 지표**: precision/recall, confusion matrix 등 필요 시 확장\n- **모델 병합 저장**: `peft_model.merge_and_unload()` 사용 가능"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ✅ (선택) 미니 샌티티 체크"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# 전체 학습 전에 파이프라인 점검용 소량 데이터로 1 epoch만 빠르게 검증하고 싶다면\n# 아래 예시를 참고해 주석 해제/수정하여 사용하세요.\n\n# mini_train = tok_datasets[\"train\"].select(range(min(256, len(tok_datasets[\"train\"]))))\n# mini_test  = tok_datasets[\"test\"].select(range(min(256, len(tok_datasets[\"test\"]))))\n\n# args_quick = TrainingArguments(\n#     output_dir=os.path.join(OUT_DIR, \"quick_tmp\"),\n#     per_device_train_batch_size=16,\n#     per_device_eval_batch_size=16,\n#     learning_rate=5e-5,\n#     num_train_epochs=1,\n#     evaluation_strategy=\"epoch\",\n#     logging_steps=20,\n#     report_to=[],\n#     seed=SEED\n# )\n# quick_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=NUM_LABELS)\n# quick_tr = Trainer(\n#     model=quick_model, args=args_quick,\n#     train_dataset=mini_train, eval_dataset=mini_test,\n#     tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics\n# )\n# quick_tr.train(); print(quick_tr.evaluate())"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}