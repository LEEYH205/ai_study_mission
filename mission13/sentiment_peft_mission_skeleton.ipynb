{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# ì‡¼í•‘ëª° ë¦¬ë·° ê°ì„± ë¶„ì„ â€” **Full Fine-Tuning vs PEFT (LoRA)** ìŠ¤ì¼ˆë ˆí†¤\n\n> ë²„ì „: 2025-09-03 Â· ì‘ì„±ì: *ìŠ¤ì¼ˆë ˆí†¤ ìë™ ìƒì„±*  \në³¸ ë…¸íŠ¸ë¶ì€ **ì‡¼í•‘ëª° ë¦¬ë·° ë°ì´í„°(JSON)**ë¥¼ ì´ìš©í•´ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” **ìŠ¤ì¼ˆë ˆí†¤**ì…ë‹ˆë‹¤.  \në‘ ê°€ì§€ í•™ìŠµ ë°©ì‹(**Full Fine-Tuning**, **PEFT/LoRA**)ì„ ë™ì¼ íŒŒì´í”„ë¼ì¸ì—ì„œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\n## ë¯¸ì…˜ ê°œìš”\n- **ë°ì´í„° ì „ì²˜ë¦¬** â†’ **í•™ìŠµ/ê²€ì¦ ë¶„í• ** â†’ **í† í¬ë‚˜ì´ì§•/ë°ì´í„°ì„¸íŠ¸ êµ¬ì„±**\n- **Full FT** í•™ìŠµ/í‰ê°€/ì €ì¥\n- **PEFT(LoRA)** í•™ìŠµ/í‰ê°€/ì €ì¥\n- **í•™ìŠµ ì‹œê°„/ì •í™•ë„/ì €ì¥ ìš©ëŸ‰ ë¹„êµ** ë° ê°„ë‹¨ ì‹œê°í™”\n- ê° ì…€ì˜ ì˜ë„/ì„¤ëª…ì„ **ë§ˆí¬ë‹¤ìš´**ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ë¦¬í¬íŠ¸ì²˜ëŸ¼ ì½íˆë„ë¡ êµ¬ì„±\n\n> ğŸ’¡ ë³¸ ë¬¸ì„œëŠ” **ìŠ¤ì¼ˆë ˆí†¤**ì´ë¯€ë¡œ, í•„ìš”ì— ë§ê²Œ **í•˜ì´í¼íŒŒë¼ë¯¸í„°Â·ëª¨ë¸Â·ì „ì²˜ë¦¬**ë¥¼ ì¡°ì •í•˜ì„¸ìš”.  \n> ğŸ’¡ í•œêµ­ì–´ ë°ì´í„°ì— ì í•©í•œ ë² ì´ìŠ¤ ëª¨ë¸(ì˜ˆ: `klue/bert-base`)ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ§­ Runbook (ì‹¤í–‰ ê°€ì´ë“œ)\n\n1. **í™˜ê²½ ì¤€ë¹„**\n   - (ë¡œì»¬/Colab) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:\n     ```bash\n     pip install -q \"transformers>=4.41.0\" \"datasets>=2.19.0\" \"peft>=0.11.0\" \"accelerate>=0.32.0\" evaluate scikit-learn matplotlib pandas\n     ```\n   - GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ `accelerate`ê°€ ì•Œì•„ì„œ ìµœì  ê¸°ê¸°ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n\n2. **ë°ì´í„° ìœ„ì¹˜ ì§€ì •**\n   - ë°ì´í„°ëŠ” **JSON íŒŒì¼**ì´ë©°, í•„ë“œ:\n     - `RawText`: ë¦¬ë·° í…ìŠ¤íŠ¸\n     - `GeneralPolarity`: ê°ì„± ë ˆì´ë¸” (`-1`=ë¶€ì •, `0`=ì¤‘ë¦½, `1`=ê¸ì •)\n   - zip ì••ì¶•ì´ë¼ë©´ ë…¸íŠ¸ë¶ê³¼ ê°™ì€ í´ë”ì— ë‘ê³ , ì•„ë˜ **ë°ì´í„° ë¡œë“œ** ì…€ì—ì„œ ê²½ë¡œ(`DATA_ZIP_PATH`/`DATA_DIR`)ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n\n3. **ì „ì²˜ë¦¬ & ë¶„í• **\n   - ë¶ˆìš©ì–´ ì²˜ë¦¬/ì´ëª¨ì§€ ì œê±° ë“±ì€ **ì„ íƒ**ì…ë‹ˆë‹¤. ìš°ì„ ì€ ìµœì†Œ ì „ì²˜ë¦¬ë¡œ ì‹œì‘í•˜ì„¸ìš”.\n   - ê¸°ë³¸ì€ **3-í´ë˜ìŠ¤(ë¶€ì •/ì¤‘ë¦½/ê¸ì •)** ë¶„ë¥˜. ì›í•˜ë©´ ì¤‘ë¦½ì„ ì œì™¸í•´ **2-í´ë˜ìŠ¤**ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n4. **í•™ìŠµ**\n   - **Full FT** â†’ **PEFT(LoRA)** ìˆœìœ¼ë¡œ ì‹¤í–‰.\n   - ê° í•™ìŠµ ë¸”ë¡ì€ **ì‹œê°„ ì¸¡ì •** ë° **ë©”íŠ¸ë¦­**ì„ ìë™ ë¡œê¹…í•©ë‹ˆë‹¤.\n\n5. **ë¹„êµ & ë¦¬í¬íŠ¸**\n   - í•™ìŠµ ì‹œê°„, ì •í™•ë„/F1, ì €ì¥ ìš©ëŸ‰(MB)ì„ í‘œ/ì°¨íŠ¸ë¡œ ë¹„êµ.\n   - í•„ìš”í•œ ê²½ìš° WandB/MLflow ì—°ë™ ì„¹ì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜ (í•„ìš” ì‹œ ì‹¤í–‰)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Colab/ë¡œì»¬ì—ì„œ í•„ìš” ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰\n# %pip install -q \"transformers>=4.41.0\" \"datasets>=2.19.0\" \"peft>=0.11.0\" \"accelerate>=0.32.0\" evaluate scikit-learn matplotlib pandas\n\nimport os, sys, math, time, json, random, shutil, pathlib, zipfile\nfrom typing import List, Dict, Any, Optional\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nprint(f\"PyTorch: {torch.__version__}, CUDA available: {torch.cuda.is_available()}\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\n\nimport evaluate\nfrom datasets import Dataset, DatasetDict\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer,\n    set_seed\n)\n\nfrom peft import LoraConfig, get_peft_model, TaskType"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## âš™ï¸ ì„¤ì • (ê²½ë¡œ/ëª¨ë¸/í•˜ì´í¼íŒŒë¼ë¯¸í„°)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# === ë°ì´í„° ê²½ë¡œ ===\nDATA_ZIP_PATH = \"review-sentiment-analysis.zip\"   # ì˜ˆ: ë…¸íŠ¸ë¶ê³¼ ê°™ì€ í´ë”ì— ìœ„ì¹˜\nDATA_DIR = \"data\"                                  # ì••ì¶• í•´ì œë  í´ë”\n\n# ì§ì ‘ JSON í´ë”ë¥¼ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (zip ë¯¸ì‚¬ìš© ì‹œ)\n# DATA_DIR = \"/path/to/json_dir\"\n\n# JSON íŒŒì¼ì„ ì°¾ì„ ê¸€ë¡­ íŒ¨í„´ (í•˜ìœ„ í´ë” í¬í•¨)\nGLOB_PATTERN = \"**/*.json\"\n\n# í•„ë“œëª… (ë°ì´í„°ì…‹ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€ê²½ ê°€ëŠ¥)\nTEXT_FIELD = \"RawText\"\nLABEL_FIELD = \"GeneralPolarity\"\n\n# ë¼ë²¨ ë§¤í•‘ (3-í´ë˜ìŠ¤)\nLABEL_MAP = {-1: 0, 0: 1, 1: 2}\nID2LABEL = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\nLABEL2ID = {v: k for k, v in ID2LABEL.items()}\n\n# ì¤‘ë¦½ ì œì™¸í•˜ê³  2-í´ë˜ìŠ¤(Binary)ë¡œ ë°”ê¾¸ë ¤ë©´ ì•„ë˜ í”Œë˜ê·¸ ì‚¬ìš©\nBINARY_CLASS = False  # Trueë¡œ ë‘ë©´ neutral ì œì™¸ (ë¶€ì •/ê¸ì •ë§Œ)\n\n# ì„ íƒì  ë„ë©”ì¸ í•„í„° (ì˜ˆ: [\"íŒ¨ì…˜\", \"í™”ì¥í’ˆ\"] ë“±). ë©”íƒ€ì— domain í‚¤ê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©\nDOMAIN_FILTER: Optional[list] = None  # ë˜ëŠ” [\"íŒ¨ì…˜\", \"í™”ì¥í’ˆ\"]\n\n# === ëª¨ë¸ & í† í¬ë‚˜ì´ì € ===\nBASE_MODEL_NAME = \"klue/bert-base\"\nMAX_LENGTH = 256\n\n# === í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° ===\nSEED = 42\nEPOCHS = 2\nBATCH_SIZE = 16\nLR_FT = 5e-5\nLR_PEFT = 5e-5\n\n# ì¶œë ¥/ì €ì¥ ê²½ë¡œ\nOUT_DIR = \"outputs\"\nFT_DIR = os.path.join(OUT_DIR, \"full_ft_model\")\nPEFT_DIR = os.path.join(OUT_DIR, \"peft_lora_adapter\")\n\nos.makedirs(OUT_DIR, exist_ok=True)\n\nset_seed(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n\ndef human_mb(bytes_size: int) -> float:\n    return round(bytes_size / (1024 * 1024), 2)\n\ndef dir_size_mb(path: str) -> float:\n    total = 0\n    for root, _, files in os.walk(path):\n        for f in files:\n            fp = os.path.join(root, f)\n            if os.path.isfile(fp):\n                total += os.path.getsize(fp)\n    return human_mb(total)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ“¥ ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ndef _extract_records_from_json(obj):\n    r\"\"\"\n    ë‹¤ì–‘í•œ JSON ìŠ¤í‚¤ë§ˆë¥¼ ìµœëŒ€í•œ ê²¬ê³ í•˜ê²Œ íŒŒì‹±í•˜ì—¬\n    [{TEXT_FIELD: str, LABEL_FIELD: int, ...(optional: domain)}] ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.\n    \"\"\"\n    records = []\n    if isinstance(obj, list):\n        for item in obj:\n            if isinstance(item, dict):\n                records.append(item)\n    elif isinstance(obj, dict):\n        if \"reviews\" in obj and isinstance(obj[\"reviews\"], list):\n            for item in obj[\"reviews\"]:\n                if isinstance(item, dict):\n                    records.append(item)\n        else:\n            records.append(obj)\n    return records\n\ndef load_json_files(data_dir: str, glob_pattern: str = \"**/*.json\") -> pd.DataFrame:\n    import glob\n    paths = glob.glob(os.path.join(data_dir, glob_pattern), recursive=True)\n    rows = []\n    for p in paths:\n        try:\n            with open(p, \"r\", encoding=\"utf-8\") as f:\n                obj = json.load(f)\n            recs = _extract_records_from_json(obj)\n            for r in recs:\n                if TEXT_FIELD in r and LABEL_FIELD in r:\n                    rows.append({\n                        \"text\": str(r[TEXT_FIELD]),\n                        \"label_raw\": r[LABEL_FIELD],\n                        \"domain\": r.get(\"domain\") or r.get(\"category\") or None,\n                        \"__src__\": p\n                    })\n        except Exception as e:\n            print(f\"[WARN] JSON parse failed: {p} -> {e}\")\n    df = pd.DataFrame(rows)\n    return df\n\ndef basic_clean(text: str) -> str:\n    text = text.replace(\"\\n\", \" \").strip()\n    return text\n\n# Zip í•´ì œ (ì¡´ì¬í•  ê²½ìš°)\nif os.path.exists(DATA_ZIP_PATH):\n    print(f\"Unzipping: {DATA_ZIP_PATH} -> {DATA_DIR}\")\n    os.makedirs(DATA_DIR, exist_ok=True)\n    with zipfile.ZipFile(DATA_ZIP_PATH, 'r') as zf:\n        zf.extractall(DATA_DIR)\n\ndf = load_json_files(DATA_DIR, GLOB_PATTERN)\nif len(df) == 0:\n    raise RuntimeError(\"ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. DATA_ZIP_PATH/DATA_DIR ê²½ë¡œì™€ JSON ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n\nif DOMAIN_FILTER:\n    df = df[df[\"domain\"].isin(DOMAIN_FILTER)]\n\nif BINARY_CLASS:\n    df = df[df[\"label_raw\"].isin([-1, 1])].copy()\n    df[\"label\"] = (df[\"label_raw\"] == 1).astype(int)\n    ID2LABEL = {0: \"negative\", 1: \"positive\"}\n    LABEL2ID = {v: k for k, v in ID2LABEL.items()}\n    NUM_LABELS = 2\nelse:\n    df[\"label\"] = df[\"label_raw\"].map(LABEL_MAP)\n    NUM_LABELS = 3\n\ndf[\"text\"] = df[\"text\"].astype(str).map(basic_clean)\ndf = df.dropna(subset=[\"text\", \"label\"]).reset_index(drop=True)\n\nprint(\"ìƒ˜í”Œ:\")\ndisplay(df.head(3))\nprint(\"ë¼ë²¨ ë¶„í¬:\")\ndisplay(df[\"label\"].value_counts(normalize=False).rename_axis(\"label\").to_frame(\"count\"))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ”€ í•™ìŠµ/ê²€ì¦ ë¶„í• "
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ntrain_df, test_df = train_test_split(\n    df, \n    test_size=0.2, \n    random_state=SEED, \n    stratify=df[\"label\"]\n)\nprint(f\"train={len(train_df)}, test={len(test_df)}\")\n\ntrain_ds = Dataset.from_pandas(train_df[[\"text\",\"label\"]], preserve_index=False)\ntest_ds  = Dataset.from_pandas(test_df[[\"text\",\"label\"]], preserve_index=False)\nraw_datasets = DatasetDict({\"train\": train_ds, \"test\": test_ds})\nraw_datasets"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ”¡ í† í¬ë‚˜ì´ì € & ë°ì´í„°ì…‹ êµ¬ì„±"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, use_fast=True)\n\ndef tokenize_fn(batch):\n    return tokenizer(\n        batch[\"text\"],\n        truncation=True,\n        max_length=MAX_LENGTH\n    )\n\ntok_datasets = raw_datasets.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntok_datasets"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ§  Baseline: Full Fine-Tuning"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nft_model = AutoModelForSequenceClassification.from_pretrained(\n    BASE_MODEL_NAME, \n    num_labels=NUM_LABELS, \n    id2label=ID2LABEL, \n    label2id=LABEL2ID\n)\n\nmetric_accuracy = evaluate.load(\"accuracy\")\nmetric_f1 = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    acc = metric_accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n    f1_macro = metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n    return {\"accuracy\": acc, \"f1_macro\": f1_macro}\n\nft_args = TrainingArguments(\n    output_dir=os.path.join(OUT_DIR, \"ft_tmp\"),\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    learning_rate=LR_FT,\n    num_train_epochs=EPOCHS,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    greater_is_better=True,\n    report_to=[],\n    seed=SEED\n)\n\nft_trainer = Trainer(\n    model=ft_model,\n    args=ft_args,\n    train_dataset=tok_datasets[\"train\"],\n    eval_dataset=tok_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nt0 = time.perf_counter()\nft_train_out = ft_trainer.train()\nft_train_sec = time.perf_counter() - t0\n\nft_eval = ft_trainer.evaluate()\nprint(\"Full FT eval:\", ft_eval)\n\n# ì €ì¥\nif os.path.exists(OUT_DIR):\n    os.makedirs(OUT_DIR, exist_ok=True)\nif os.path.exists(\"ft_tmp\"):\n    pass\n\nif os.path.exists(FT_DIR):\n    import shutil as _shutil\n    _shutil.rmtree(FT_DIR)\nft_trainer.save_model(FT_DIR)\ntokenizer.save_pretrained(FT_DIR)\n\nft_size_mb = dir_size_mb(FT_DIR)\nprint(f\"[Full FT] ì €ì¥ ìš©ëŸ‰: {ft_size_mb} MB\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ”§ PEFT (LoRA) í•™ìŠµ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\npeft_base = AutoModelForSequenceClassification.from_pretrained(\n    BASE_MODEL_NAME, \n    num_labels=NUM_LABELS, \n    id2label=ID2LABEL, \n    label2id=LABEL2ID\n)\n\ntarget_modules = [\"query\", \"key\", \"value\", \"dense\"]\n\nlora_cfg = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    inference_mode=False,\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    target_modules=target_modules\n)\n\npeft_model = get_peft_model(peft_base, lora_cfg)\npeft_model.print_trainable_parameters()\n\npeft_args = TrainingArguments(\n    output_dir=os.path.join(OUT_DIR, \"peft_tmp\"),\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    learning_rate=LR_PEFT,\n    num_train_epochs=EPOCHS,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    greater_is_better=True,\n    report_to=[],\n    seed=SEED\n)\n\npeft_trainer = Trainer(\n    model=peft_model,\n    args=peft_args,\n    train_dataset=tok_datasets[\"train\"],\n    eval_dataset=tok_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\nt0 = time.perf_counter()\npeft_train_out = peft_trainer.train()\npeft_train_sec = time.perf_counter() - t0\n\npeft_eval = peft_trainer.evaluate()\nprint(\"PEFT eval:\", peft_eval)\n\n# ì–´ëŒ‘í„°ë§Œ ì €ì¥\nimport shutil as _shutil\nif os.path.exists(PEFT_DIR):\n    _shutil.rmtree(PEFT_DIR)\npeft_trainer.model.save_pretrained(PEFT_DIR)\ntokenizer.save_pretrained(PEFT_DIR)\n\npeft_size_mb = dir_size_mb(PEFT_DIR)\nprint(f\"[PEFT] ì €ì¥ ìš©ëŸ‰(ì–´ëŒ‘í„°): {peft_size_mb} MB\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ“Š ë‘ ë°©ì‹ ë¹„êµ (ì‹œê°„ Â· ì •í™•ë„ Â· ìš©ëŸ‰)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport pandas as _pd\nsummary = _pd.DataFrame([\n    {\n        \"approach\": \"Full FT\",\n        \"train_sec\": round(ft_train_sec, 2),\n        \"accuracy\": round(float(ft_eval.get(\"eval_accuracy\", float(\"nan\"))), 4),\n        \"f1_macro\": round(float(ft_eval.get(\"eval_f1_macro\", float(\"nan\"))), 4),\n        \"saved_size_mb\": ft_size_mb\n    },\n    {\n        \"approach\": \"PEFT (LoRA)\",\n        \"train_sec\": round(peft_train_sec, 2),\n        \"accuracy\": round(float(peft_eval.get(\"eval_accuracy\", float(\"nan\"))), 4),\n        \"f1_macro\": round(float(peft_eval.get(\"eval_f1_macro\", float(\"nan\"))), 4),\n        \"saved_size_mb\": peft_size_mb\n    }\n])\n\ndisplay(summary)\n\nimport matplotlib.pyplot as _plt\n\n_plt.figure()\n_plt.bar(summary[\"approach\"], summary[\"saved_size_mb\"])\n_plt.title(\"ì €ì¥ ìš©ëŸ‰ ë¹„êµ (MB)\")\n_plt.ylabel(\"MB\")\n_plt.show()\n\n_plt.figure()\n_plt.bar(summary[\"approach\"], summary[\"accuracy\"])\n_plt.title(\"ì •í™•ë„(Accuracy) ë¹„êµ\")\n_plt.ylabel(\"accuracy\")\n_plt.ylim(0, 1)\n_plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ğŸ“ ì°¸ê³  & íŠ¸ëŸ¬ë¸”ìŠˆíŒ…"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "- **JSON ìŠ¤í‚¤ë§ˆê°€ ë‹¤ë¥¸ ê²½ìš°**: `TEXT_FIELD`, `LABEL_FIELD`, `_extract_records_from_json()` ìˆ˜ì •\n- **2-í´ë˜ìŠ¤(ë¶€ì •/ê¸ì •)ë§Œ ì‚¬ìš©**: `BINARY_CLASS=True` ì„¤ì •\n- **PEFT íƒ€ê¹ƒ ëª¨ë“ˆ ì—ëŸ¬**: ëª¨ë¸ êµ¬ì¡°ì— ë§ê²Œ `target_modules` ìˆ˜ì • (ì˜ˆ: `query_proj`, `value_proj` ë“±)\n- **ì†ë„ ê°œì„ **: `fp16=True`(AMP), `gradient_accumulation_steps`, ì§§ì€ `MAX_LENGTH` ë“±\n- **ì¶”ê°€ ì§€í‘œ**: precision/recall, confusion matrix ë“± í•„ìš” ì‹œ í™•ì¥\n- **ëª¨ë¸ ë³‘í•© ì €ì¥**: `peft_model.merge_and_unload()` ì‚¬ìš© ê°€ëŠ¥"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## âœ… (ì„ íƒ) ë¯¸ë‹ˆ ìƒŒí‹°í‹° ì²´í¬"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# ì „ì²´ í•™ìŠµ ì „ì— íŒŒì´í”„ë¼ì¸ ì ê²€ìš© ì†ŒëŸ‰ ë°ì´í„°ë¡œ 1 epochë§Œ ë¹ ë¥´ê²Œ ê²€ì¦í•˜ê³  ì‹¶ë‹¤ë©´\n# ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ ì£¼ì„ í•´ì œ/ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\n\n# mini_train = tok_datasets[\"train\"].select(range(min(256, len(tok_datasets[\"train\"]))))\n# mini_test  = tok_datasets[\"test\"].select(range(min(256, len(tok_datasets[\"test\"]))))\n\n# args_quick = TrainingArguments(\n#     output_dir=os.path.join(OUT_DIR, \"quick_tmp\"),\n#     per_device_train_batch_size=16,\n#     per_device_eval_batch_size=16,\n#     learning_rate=5e-5,\n#     num_train_epochs=1,\n#     evaluation_strategy=\"epoch\",\n#     logging_steps=20,\n#     report_to=[],\n#     seed=SEED\n# )\n# quick_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=NUM_LABELS)\n# quick_tr = Trainer(\n#     model=quick_model, args=args_quick,\n#     train_dataset=mini_train, eval_dataset=mini_test,\n#     tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics\n# )\n# quick_tr.train(); print(quick_tr.evaluate())"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}