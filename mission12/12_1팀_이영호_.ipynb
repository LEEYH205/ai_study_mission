{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d338e81",
   "metadata": {},
   "source": [
    "# ë¯¸ì…˜ ì†Œê°œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f626407",
   "metadata": {},
   "source": [
    "Hugging Face transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìš”ì•½ ëª¨ë¸ì„ êµ¬í˜„í•˜ëŠ” ë¯¸ì…˜.\n",
    "ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ ì‹¤í–‰, ê²°ê³¼ í‰ê°€ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83904421",
   "metadata": {},
   "source": [
    "## ì‚¬ìš© ë°ì´í„°ì…‹\n",
    "- ë°ì´í„° í˜•ì‹\n",
    "    - JSON íŒŒì¼ í˜•íƒœë¡œ ì œê³µë˜ë©°, 3ì¢…ë¥˜(ì‹ ë¬¸ ê¸°ì‚¬, ì‚¬ì„¤, ë²•ë¥ )ì˜ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.\n",
    "- ë°ì´í„° êµ¬ì„±\n",
    "    - ê° ë¬¸ì„œ íƒ€ì…ì€ train/test ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì „ì²´ ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ê±°ë‚˜ ì›í•˜ëŠ” ë¬¸ì„œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì—¬ í•™ìŠµì‹œí‚¤ë©´ ëœë‹¤.\n",
    "\n",
    "## ê°€ì´ë“œë¼ì¸\n",
    "- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "    - ë¬¸ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ë¶ˆí•„ìš”í•œ ê¸°í˜¸ë‚˜ ê³µë°±ì„ ì œê±°í•˜ëŠ” ë“± ì „ì²˜ë¦¬ ì‘ì—…ì„ ìˆ˜í–‰\n",
    "    - í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ í™•ì¸í•˜ê³ , ëª¨ë¸ ì…ë ¥ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•œë‹¤.\n",
    "- ëª¨ë¸ ì„ íƒ ë° ì‹¤í–‰\n",
    "    - Hugging Faceì˜ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ë¬¸ì„œ ìš”ì•½ì„ ìˆ˜í–‰\n",
    "    - ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•˜ê±°ë‚˜ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê°€ì§€ê³  Fine-tuning í•˜ê¸°.\n",
    "- ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ë¶„ì„\n",
    "    - ìƒì„±ëœ ìš”ì•½ë¬¸ê³¼ ì›ë³¸ ë¬¸ì„œë¥¼ ë¹„êµí•˜ì—¬ ROUGE ë“±ì˜ í‰ê°€ ì§€í‘œë¥¼ ì‚¬ìš©í•´ ìš”ì•½ í’ˆì§ˆì„ ë¶„ì„í•œë‹¤.\n",
    "    - í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•œ ìš”ì•½ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•œë‹¤.\n",
    "- ëª¨ë¸ êµ¬í˜„ ë° í•™ìŠµ ê²°ê³¼\n",
    "    - ë¬¸ì„œ ìš”ì•½ ëª¨ë¸(ì˜ˆ: Transformer ê¸°ë°˜ ìš”ì•½ ëª¨ë¸, T5, BART ë“±)ì„ êµ¬í˜„í•˜ê³ , ë°ì´í„° ë¡œë“œ â†’ ì „ì²˜ë¦¬ â†’ ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ â†’ ìš”ì•½ ìƒì„± ë° í‰ê°€ ê³¼ì •ì„ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰.\n",
    "- ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ì œì¶œ\n",
    "    - ìƒì„±ëœ ìš”ì•½ë¬¸ì˜ í’ˆì§ˆì„ ì •ì„±ì (ìš”ì•½ ê²°ê³¼ í™•ì¸) ë° ì •ëŸ‰ì (ROUGE ë“±)ìœ¼ë¡œ í‰ê°€.\n",
    "    - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ ìš”ì•½ ê²°ê³¼ë¥¼ í¬í•¨\n",
    "- ì›ë³¸ ë°ì´í„°ì…‹ ë§í¬\n",
    "    - https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=97"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda3cf7b",
   "metadata": {},
   "source": [
    "# í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (4.55.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from datasets) (2.3.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5/5\u001b[0m [datasets]4/5\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datasets-4.0.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Requirement already satisfied: konlpy in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from konlpy) (1.5.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from konlpy) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb10b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196d8af",
   "metadata": {},
   "source": [
    "## GPU ì„¸íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.8.0\n",
      "MPS available: True\n",
      "CUDA available: False\n",
      "Using MPS (Apple Silicon GPU)\n",
      "Selected device: mps\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # ë§¥ë¶ M1/M2 GPU\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # NVIDIA GPU (Colab, Windows ë“±)\n",
    "    print(\"Using CUDA (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # CPU fallback\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"Selected device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a998bca",
   "metadata": {},
   "source": [
    "# KoBART ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe02291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== gogamza/kobart-base-v2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\n",
      "\n",
      "ï¿½ï¿½ ëª¨ë¸ ì •ë³´:\n",
      "- í† í¬ë‚˜ì´ì € íƒ€ì…: PreTrainedTokenizerFast\n",
      "- ëª¨ë¸ íƒ€ì…: BartForConditionalGeneration\n",
      "- ì–´íœ˜ í¬ê¸°: 30,000\n",
      "- ëª¨ë¸ íŒŒë¼ë¯¸í„°: 123,859,968\n",
      "\n",
      "ï¿½ï¿½ ëª¨ë¸ì´ mps ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# KoBART ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "print(\"=== gogamza/kobart-base-v2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ===\")\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ (models í´ë”ì— ì €ì¥)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gogamza/kobart-base-v2', cache_dir='./models')\n",
    "print(\"âœ… í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (models í´ë”ì— ì €ì¥)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('gogamza/kobart-base-v2', cache_dir='./models')\n",
    "print(\"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
    "print(f\"\\nï¿½ï¿½ ëª¨ë¸ ì •ë³´:\")\n",
    "print(f\"- í† í¬ë‚˜ì´ì € íƒ€ì…: {type(tokenizer).__name__}\")\n",
    "print(f\"- ëª¨ë¸ íƒ€ì…: {type(model).__name__}\")\n",
    "print(f\"- ì–´íœ˜ í¬ê¸°: {tokenizer.vocab_size:,}\")\n",
    "print(f\"- ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "model = model.to(device)\n",
    "print(f\"\\nï¿½ï¿½ ëª¨ë¸ì´ {device} ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c453213",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf6d7c",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1baf49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def load_json_dataset(file_path):\n",
    "    \"\"\"JSON íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ ë¬¸ì„œë³„ text, summary ì •ë³´ë¥¼ ì¶”ì¶œ\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    examples = []\n",
    "    for doc in data[\"documents\"]:\n",
    "        sentences = []\n",
    "        # \"text\"ëŠ” ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ë¯€ë¡œ ë‚´ë¶€ì˜ ëª¨ë“  sentenceë¥¼ ì¶”ì¶œ\n",
    "        for sublist in doc[\"text\"]:\n",
    "            for item in sublist:\n",
    "                sentences.append(item.get(\"sentence\", \"\"))\n",
    "        \n",
    "        full_text = \" \".join(sentences)\n",
    "        # abstractive ìš”ì•½ì€ ì²«ë²ˆì§¸ í•­ëª© ì‚¬ìš© (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)\n",
    "        summary = doc[\"abstractive\"][0] if doc[\"abstractive\"] else \"\"\n",
    "        \n",
    "        examples.append({\n",
    "            \"text\": full_text,\n",
    "            \"summary\": summary,\n",
    "        })\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c7360",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„°ì…‹ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a109f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë°ì´í„° ë¡œë“œ ì¤‘ ===\n",
      "í›ˆë ¨ ë°ì´í„°: 24,329ê°œ\n",
      "ê²€ì¦ ë°ì´í„°: 3,004ê°œ\n",
      "\n",
      "=== ìƒ˜í”Œ ë°ì´í„° ===\n",
      "ì²« ë²ˆì§¸ í›ˆë ¨ ì˜ˆì‹œ:\n",
      "í…ìŠ¤íŠ¸ ê¸¸ì´: 372ì\n",
      "ìš”ì•½ ê¸¸ì´: 97ì\n",
      "í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: ì›ê³ ê°€ ì†Œì†íšŒì‚¬ì˜ ë…¸ë™ì¡°í•©ì—ì„œ ë¶„ê·œê°€ ë°œìƒí•˜ì ë…¸ì¡°í™œë™ì„ êµ¬ì‹¤ë¡œ ì •ìƒì ì¸ ê·¼ë¬´ë¥¼ í•´íƒœí•˜ê³ , ë…¸ì¡°ì¡°í•©ì¥ì´ ì‚¬ì„í•œ ê²½ìš°, ë…¸ë™ì¡°í•©ê·œì•½ì— ë™ ì¡°í•©ì¥ì˜ ì§ë¬´ë¥¼ ëŒ€í–‰í•  ìë¥¼ ê·œì •í•´ ë‘ê³  ìˆ...\n",
      "ìš”ì•½: ì›ê³ ê°€  ì£¼ë™í•˜ì—¬ íšŒì‚¬ì—…ë¬´ëŠ¥ë¥ ì„ ì €í•´í•˜ê³  íšŒì‚¬ì—…ë¬´ìƒì˜ ì§€íœ˜ëª…ë ¹ì— ìœ„ë°˜í•˜ì˜€ë‹¤ë©´ ì´ì— ë”°ë¥¸ ì§•ê³„í•´ê³ ëŠ” ì‚¬ë‚´ì§ˆì„œë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•œ ì‚¬ìš©ì ê³ ìœ ì˜ ì •ë‹¹í•œ ì§•ê³„ê¶Œì˜ í–‰ì‚¬ë¡œ ë³´ì•„ì•¼ í•œë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "base_path = \"./summarization/\"\n",
    "\n",
    "# ì²˜ìŒì—ëŠ” ì‘ì€ ë²•ë¥  ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹œì‘\n",
    "train_file = \"train_original_law.json\"\n",
    "valid_file = \"valid_original_law.json\"\n",
    "\n",
    "print(\"=== ë°ì´í„° ë¡œë“œ ì¤‘ ===\")\n",
    "train_examples = load_json_dataset(os.path.join(base_path, train_file))\n",
    "valid_examples = load_json_dataset(os.path.join(base_path, valid_file))\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_examples):,}ê°œ\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(valid_examples):,}ê°œ\")\n",
    "\n",
    "# ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "print(f\"\\n=== ìƒ˜í”Œ ë°ì´í„° ===\")\n",
    "print(f\"ì²« ë²ˆì§¸ í›ˆë ¨ ì˜ˆì‹œ:\")\n",
    "print(f\"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(train_examples[0]['text'])}ì\")\n",
    "print(f\"ìš”ì•½ ê¸¸ì´: {len(train_examples[0]['summary'])}ì\")\n",
    "print(f\"í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {train_examples[0]['text'][:100]}...\")\n",
    "print(f\"ìš”ì•½: {train_examples[0]['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40499dbb",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad1518f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ===\n",
      "ì „ì²˜ë¦¬ í›„ í›ˆë ¨ ë°ì´í„°: 22,514ê°œ\n",
      "ì „ì²˜ë¦¬ í›„ ê²€ì¦ ë°ì´í„°: 2,836ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def preprocess_data(examples, max_text_length=512, max_summary_length=128):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì™€ ìš”ì•½ì„ ì „ì²˜ë¦¬í•˜ê³  ê¸¸ì´ ì œí•œ\"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    for example in examples:\n",
    "        text = example[\"text\"].strip()\n",
    "        summary = example[\"summary\"].strip()\n",
    "        \n",
    "        # ë¹ˆ ìš”ì•½ ì œê±°\n",
    "        if not summary:\n",
    "            continue\n",
    "            \n",
    "        # ê¸¸ì´ ì œí•œ\n",
    "        if len(text) > max_text_length * 3:  # ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì •\n",
    "            continue\n",
    "        if len(summary) > max_summary_length * 3:\n",
    "            continue\n",
    "            \n",
    "        processed.append({\n",
    "            \"text\": text,\n",
    "            \"summary\": summary\n",
    "        })\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬ ì ìš©\n",
    "print(\"=== ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ===\")\n",
    "train_processed = preprocess_data(train_examples)\n",
    "valid_processed = preprocess_data(valid_examples)\n",
    "\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ í›ˆë ¨ ë°ì´í„°: {len(train_processed):,}ê°œ\")\n",
    "print(f\"ì „ì²˜ë¦¬ í›„ ê²€ì¦ ë°ì´í„°: {len(valid_processed):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d65a09",
   "metadata": {},
   "source": [
    "## 4. Hugging Face Datasetìœ¼ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2be1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset ë³€í™˜ ì™„ë£Œ ===\n",
      "ë°ì´í„°ì…‹ êµ¬ì¡°: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 22514\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'summary'],\n",
      "        num_rows: 2836\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Dataset ê°ì²´ ìƒì„±\n",
    "train_dataset = Dataset.from_list(train_processed)\n",
    "valid_dataset = Dataset.from_list(valid_processed)\n",
    "\n",
    "# DatasetDict í˜•íƒœë¡œ í†µí•©\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": valid_dataset\n",
    "})\n",
    "\n",
    "print(\"=== Dataset ë³€í™˜ ì™„ë£Œ ===\")\n",
    "print(f\"ë°ì´í„°ì…‹ êµ¬ì¡°: {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b4c3a",
   "metadata": {},
   "source": [
    "## 5. tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4efee947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== í† í¬ë‚˜ì´ì§• ì¤‘ ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1d998d5d924aeb895345a8d169c374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4745f43b2aa0405aabd489d87ec96189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2836 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í† í¬ë‚˜ì´ì§• ì™„ë£Œ!\n",
      "í† í¬ë‚˜ì´ì§•ëœ í›ˆë ¨ ë°ì´í„°: 22514ê°œ\n",
      "í† í¬ë‚˜ì´ì§•ëœ ê²€ì¦ ë°ì´í„°: 2836ê°œ\n"
     ]
    }
   ],
   "source": [
    "# í† í¬ë‚˜ì´ì§• í•¨ìˆ˜\n",
    "def tokenize_function(example):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ì™€ ìš”ì•½ì„ í† í°í™”\"\"\"\n",
    "    model_inputs = tokenizer(\n",
    "        example[\"text\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        text_target=example[\"summary\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# í† í¬ë‚˜ì´ì§• ì ìš©\n",
    "print(\"=== í† í¬ë‚˜ì´ì§• ì¤‘ ===\")\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(f\"âœ… í† í¬ë‚˜ì´ì§• ì™„ë£Œ!\")\n",
    "print(f\"í† í¬ë‚˜ì´ì§•ëœ í›ˆë ¨ ë°ì´í„°: {len(tokenized_datasets['train'])}ê°œ\")\n",
    "print(f\"í† í¬ë‚˜ì´ì§•ëœ ê²€ì¦ ë°ì´í„°: {len(tokenized_datasets['validation'])}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a282d",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f0f22",
   "metadata": {},
   "source": [
    "## DataCollator ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8290600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DataCollator ì„¤ì • ì¤‘ ===\n",
      "âœ… DataCollator ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# DataCollator ì„¤ì •\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "print(\"=== DataCollator ì„¤ì • ì¤‘ ===\")\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(\"âœ… DataCollator ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7fb3de",
   "metadata": {},
   "source": [
    "## í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b6e9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • ì¤‘ ===\n",
      "âœ… í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\n",
      "í•™ìŠµ ì—í¬í¬: 3\n",
      "í•™ìŠµë¥ : 5e-05\n",
      "ë°°ì¹˜ í¬ê¸°: 4\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "print(\"=== í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • ì¤‘ ===\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           # ê²°ê³¼ ì €ì¥ í´ë”\n",
    "    eval_strategy=\"steps\",            # í‰ê°€ ì „ëµ\n",
    "    eval_steps=500,                   # 500 ìŠ¤í…ë§ˆë‹¤ í‰ê°€\n",
    "    save_strategy=\"steps\",            # ì €ì¥ ì „ëµ\n",
    "    save_steps=1000,                  # 1000 ìŠ¤í…ë§ˆë‹¤ ëª¨ë¸ ì €ì¥\n",
    "    learning_rate=5e-5,               # í•™ìŠµë¥ \n",
    "    per_device_train_batch_size=4,    # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •)\n",
    "    per_device_eval_batch_size=4,     # í‰ê°€ ë°°ì¹˜ í¬ê¸°\n",
    "    num_train_epochs=3,               # í•™ìŠµ ì—í¬í¬\n",
    "    weight_decay=0.01,                # ê°€ì¤‘ì¹˜ ê°ì‡ \n",
    "    logging_dir=\"./logs\",             # ë¡œê·¸ ì €ì¥ í´ë”\n",
    "    logging_steps=100,                # 100 ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸\n",
    "    save_total_limit=3,               # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ë§Œ ì €ì¥\n",
    "    load_best_model_at_end=True,      # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n",
    "    metric_for_best_model=\"eval_loss\", # ìµœê³  ì„±ëŠ¥ ê¸°ì¤€\n",
    "    greater_is_better=False,          # ì†ì‹¤ì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ\n",
    "    report_to=\"none\",                 # wandb ë“± ì™¸ë¶€ ë„êµ¬ ì‚¬ìš© ì•ˆí•¨\n",
    ")\n",
    "\n",
    "print(\"âœ… í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"í•™ìŠµ ì—í¬í¬: {training_args.num_train_epochs}\")\n",
    "print(f\"í•™ìŠµë¥ : {training_args.learning_rate}\")\n",
    "print(f\"ë°°ì¹˜ í¬ê¸°: {training_args.per_device_train_batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6c54b",
   "metadata": {},
   "source": [
    "## Trainer ì„¤ì • ë° í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480ab0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Trainer ì„¤ì • ì¤‘ ===\n",
      "âœ… Trainer ì„¤ì • ì™„ë£Œ!\n",
      "í›ˆë ¨ ë°ì´í„° í¬ê¸°: 22514\n",
      "ê²€ì¦ ë°ì´í„° í¬ê¸°: 2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/xvtnn0v91cx8bl846n_qn4100000gn/T/ipykernel_87676/3876579206.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer ì„¤ì •\n",
    "from transformers import Trainer\n",
    "\n",
    "print(\"=== Trainer ì„¤ì • ì¤‘ ===\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                           # ëª¨ë¸\n",
    "    args=training_args,                    # í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
    "    train_dataset=tokenized_datasets[\"train\"],      # í›ˆë ¨ ë°ì´í„°\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],  # ê²€ì¦ ë°ì´í„°\n",
    "    tokenizer=tokenizer,                   # í† í¬ë‚˜ì´ì €\n",
    "    data_collator=data_collator,           # ë°ì´í„° ì½œë ˆì´í„°\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"í›ˆë ¨ ë°ì´í„° í¬ê¸°: {len(tokenized_datasets['train'])}\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„° í¬ê¸°: {len(tokenized_datasets['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e88339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘!\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1454' max='16887' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1454/16887 17:21 < 3:04:30, 1.39 it/s, Epoch 0.26/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.893400</td>\n",
       "      <td>0.752535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.817400</td>\n",
       "      <td>0.704269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leeyoungho/miniforge3/envs/ai_3/lib/python3.12/site-packages/transformers/modeling_utils.py:3909: UserWarning: Moving the following attributes in the config to the generation config: {'forced_eos_token_id': 1}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# í•™ìŠµ ì‹¤í–‰\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… í•™ìŠµ ì™„ë£Œ!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mì´ í•™ìŠµ ì‹œê°„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_result.metrics[\u001b[33m'\u001b[39m\u001b[33mtrain_runtime\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mì´ˆ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ai_3/lib/python3.12/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ai_3/lib/python3.12/site-packages/transformers/trainer.py:2587\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2581\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2582\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2585\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2586\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2587\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2588\u001b[39m ):\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2590\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2591\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
    "print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ì´ í•™ìŠµ ì‹œê°„: {train_result.metrics['train_runtime']:.2f}ì´ˆ\")\n",
    "print(f\"ì´ í•™ìŠµ ìŠ¤í…: {train_result.metrics['train_steps']}\")\n",
    "print(f\"ìµœì¢… ì†ì‹¤: {train_result.metrics['train_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a2012",
   "metadata": {},
   "source": [
    "# ìš”ì•½ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a9480",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_3 (conda)",
   "language": "python",
   "name": "ai_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
